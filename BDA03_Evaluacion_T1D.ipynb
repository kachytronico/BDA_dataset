{"cells":[{"cell_type":"markdown","id":"x3zaYPoS3wFz","metadata":{"id":"x3zaYPoS3wFz"},"source":["# BDA03 ‚Äî Tarea de Evaluaci√≥n (Ecosistema Hadoop‚ÄìSpark)\n","**Flujo ETL completo:** importaci√≥n autom√°tica ‚Üí exploraci√≥n ‚Üí limpieza (Pig) ‚Üí transformaci√≥n ‚Üí carga en Hive ‚Üí consultas HQL con JOIN.\n","\n","**Dataset:** T1D (Guertin et al., 2024) ‚Äî Virginia PrIMeD  \n","**Archivos:** `survey_data_and_results_final.xlsx` + `assay_final_genotyping_file.xlsx`  \n","**Clave de relaci√≥n esperada (a validar):** `survey.SUBJECT_ID` ‚Üî `genotyping.FID`\n"]},{"cell_type":"markdown","id":"Bs6utBjrAnxZ","metadata":{"id":"Bs6utBjrAnxZ"},"source":["## Explicaci√≥n del conjunto de datos elegido\n","He elegido un dataset real sobre **riesgo gen√©tico de Diabetes Tipo 1 (T1D)** del estudio **Guertin et al. (2024)** (cohorte Virginia PrIMeD). Es interesante porque permite combinar datos **cl√≠nicos/demogr√°ficos** con datos **gen√©ticos**, lo cual es un escenario t√≠pico de integraci√≥n (JOIN) en Big Data.\n","\n","### Archivos utilizados\n","Trabajo con **dos archivos interrelacionados**:\n","\n","1) **`survey_data_and_results_final.xlsx` (Survey / Fenotipo)**  \n","Contiene informaci√≥n del participante (cl√≠nica/demogr√°fica) y variables relacionadas con riesgo gen√©tico.  \n","**Clave:** `SUBJECT_ID`.\n","\n","2) **`assay_final_genotyping_file.xlsx` (Genotyping / Gen√©tica)**  \n","Contiene marcadores gen√©ticos (SNPs) por participante.  \n","**Clave:** `FID`.\n","\n","### Relaci√≥n entre archivos\n","La relaci√≥n se realiza por el identificador de participante:\n","- **`survey.SUBJECT_ID = genotyping.FID`**  \n","(Validar√© esta relaci√≥n con datos reales antes de continuar.)\n","\n","### Tama√±o y relevancia\n","El dataset tiene en torno a **3.800 participantes**, suficiente para demostrar un flujo ETL completo con Hadoop (Pig) y Spark/Hive, incluyendo limpieza de datos, transformaci√≥n y consultas con JOIN.\n"]},{"cell_type":"markdown","id":"CTNHxl5fvZsr","metadata":{"id":"CTNHxl5fvZsr"},"source":["# 1. Importaci√≥n autom√°tica + conversi√≥n a CSV\n","\n","\n","> Objetivo: traer los datos de forma reproducible (sin subida manual) y dejarlos en CSV para Pig/Spark/Hive.\n","\n"]},{"cell_type":"code","execution_count":1,"id":"ux6EPKfEA1uN","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":961},"collapsed":true,"executionInfo":{"elapsed":7570,"status":"ok","timestamp":1771487317292,"user":{"displayName":"Alfredo Ledesma Ruiz","userId":"02263706330541384863"},"user_tz":-60},"id":"ux6EPKfEA1uN","outputId":"f4429fdc-a170-4d80-bd09-1a7816824fec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'BDA_dataset'...\n","remote: Enumerating objects: 89, done.\u001b[K\n","remote: Counting objects: 100% (89/89), done.\u001b[K\n","remote: Compressing objects: 100% (69/69), done.\u001b[K\n","remote: Total 89 (delta 21), reused 79 (delta 14), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (89/89), 3.76 MiB | 25.34 MiB/s, done.\n","Resolving deltas: 100% (21/21), done.\n","üìÅ Repo clonado (muestra):\n","total 132K\n","drwxr-xr-x 3 root root 4.0K Feb 19 07:48 BDA03_cuadernos\n","-rw-r--r-- 1 root root 6.1K Feb 19 07:48 BDA03_Evaluacion_T1D01.ipynb\n","-rw-r--r-- 1 root root  60K Feb 19 07:48 BDA03_Evaluacion_T1D_copilot.ipynb\n","-rw-r--r-- 1 root root  41K Feb 19 07:48 BDA03_Evaluacion_T1D.ipynb\n","drwxr-xr-x 2 root root 4.0K Feb 19 07:48 Dataset not incorporated into the T1DKP\n","drwxr-xr-x 4 root root 4.0K Feb 19 07:48 docs\n","-rw-r--r-- 1 root root 7.5K Feb 19 07:48 README.md\n","\n","üìÅ RAW:\n","total 1.7M\n","-rw-r--r-- 1 root root 1.4M Feb 19 07:48 assay_final_genotyping_file.xlsx\n","-rw-r--r-- 1 root root 295K Feb 19 07:48 survey_data_and_results_final.xlsx\n","\n","üìÅ CSV:\n","total 1.8M\n","-rw-r--r-- 1 root root 1.2M Feb 19 07:48 genotyping.csv\n","-rw-r--r-- 1 root root 528K Feb 19 07:48 survey.csv\n","\n","shape survey: (3818, 15)\n","shape genotyping: (3818, 76)\n","\n","Preview survey (3 filas):\n"]},{"output_type":"display_data","data":{"text/plain":["       SUBJECT_ID  AGE   RACE    T1D_HIST AUTO_HIST  \\\n","0  10011708520314    6  White         Yes        No   \n","1  10021708520764    3  White  Don't know       Yes   \n","2  10021708521587    7  Asian  Don't know        No   \n","\n","                                           AUTO_COND AUTO_COND_4_TEXT  \\\n","0                                     Not applicable   Not applicable   \n","1  Thyroid_Hashimotos and_or Graves, Blood relati...   Not applicable   \n","2                                     Not applicable   Not applicable   \n","\n","  T1D_DIAG    T1D_DIAG_AGE        T1D_HOSP             DKA  GRS_HLA  GnonHLA  \\\n","0       No  Not applicable  Not applicable  Not applicable     1.91     0.14   \n","1       No  Not applicable  Not applicable  Not applicable    -1.41     1.93   \n","2       No  Not applicable  Not applicable  Not applicable   -13.66     0.77   \n","\n","     GRS      Risk  \n","0   2.06  Not high  \n","1   0.52  Not high  \n","2 -12.89  Not high  "],"text/html":["\n","  <div id=\"df-7068a802-5aa4-4534-9532-3a1cd038e690\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SUBJECT_ID</th>\n","      <th>AGE</th>\n","      <th>RACE</th>\n","      <th>T1D_HIST</th>\n","      <th>AUTO_HIST</th>\n","      <th>AUTO_COND</th>\n","      <th>AUTO_COND_4_TEXT</th>\n","      <th>T1D_DIAG</th>\n","      <th>T1D_DIAG_AGE</th>\n","      <th>T1D_HOSP</th>\n","      <th>DKA</th>\n","      <th>GRS_HLA</th>\n","      <th>GnonHLA</th>\n","      <th>GRS</th>\n","      <th>Risk</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10011708520314</td>\n","      <td>6</td>\n","      <td>White</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Not applicable</td>\n","      <td>Not applicable</td>\n","      <td>No</td>\n","      <td>Not applicable</td>\n","      <td>Not applicable</td>\n","      <td>Not applicable</td>\n","      <td>1.91</td>\n","      <td>0.14</td>\n","      <td>2.06</td>\n","      <td>Not high</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10021708520764</td>\n","      <td>3</td>\n","      <td>White</td>\n","      <td>Don't know</td>\n","      <td>Yes</td>\n","      <td>Thyroid_Hashimotos and_or Graves, Blood relati...</td>\n","      <td>Not applicable</td>\n","      <td>No</td>\n","      <td>Not applicable</td>\n","      <td>Not applicable</td>\n","      <td>Not applicable</td>\n","      <td>-1.41</td>\n","      <td>1.93</td>\n","      <td>0.52</td>\n","      <td>Not high</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10021708521587</td>\n","      <td>7</td>\n","      <td>Asian</td>\n","      <td>Don't know</td>\n","      <td>No</td>\n","      <td>Not applicable</td>\n","      <td>Not applicable</td>\n","      <td>No</td>\n","      <td>Not applicable</td>\n","      <td>Not applicable</td>\n","      <td>Not applicable</td>\n","      <td>-13.66</td>\n","      <td>0.77</td>\n","      <td>-12.89</td>\n","      <td>Not high</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7068a802-5aa4-4534-9532-3a1cd038e690')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7068a802-5aa4-4534-9532-3a1cd038e690 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7068a802-5aa4-4534-9532-3a1cd038e690');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"display(df_geno\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"SUBJECT_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5773503189,\n        \"min\": 10011708520314,\n        \"max\": 10021708521587,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          10011708520314,\n          10021708520764,\n          10021708521587\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AGE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 3,\n        \"max\": 7,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          6,\n          3,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RACE\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Asian\",\n          \"White\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"T1D_HIST\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Don't know\",\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUTO_HIST\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUTO_COND\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Thyroid_Hashimotos and_or Graves, Blood relative has been diagnosed with autoimmune disease but I don't know which condition\",\n          \"Not applicable\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUTO_COND_4_TEXT\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Not applicable\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"T1D_DIAG\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"T1D_DIAG_AGE\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Not applicable\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"T1D_HOSP\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Not applicable\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DKA\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Not applicable\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GRS_HLA\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.200709318914635,\n        \"min\": -13.66,\n        \"max\": 1.91,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.91\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GnonHLA\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9079831129119821,\n        \"min\": 0.14,\n        \"max\": 1.93,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GRS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.222957699838503,\n        \"min\": -12.89,\n        \"max\": 2.06,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2.06\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Risk\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Not high\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Preview genotyping (3 filas):\n"]},{"output_type":"display_data","data":{"text/plain":["              FID   contact key rs1049225 rs1052553 rs10795791 rs11203203  \\\n","0  10011708520314  CONTACT10085       C:C       A:A        A:G        A:G   \n","1  10021708520764  CONTACT14053       C:C       A:A        G:G        A:A   \n","2  10021708521587  CONTACT11350       C:C       A:G        A:G        G:G   \n","\n","  rs113010081 rs1150743 rs12416116 rs12720356  ... rs757411 rs7745656  \\\n","0         T:T       A:G        C:C        T:T  ...      C:T       G:T   \n","1         T:T       G:G        C:C        T:T  ...      C:C       T:T   \n","2         T:T       A:A        A:A        T:T  ...      C:T       T:T   \n","\n","  rs7780389 rs917911 rs9268633 rs9271366 rs9273363 rs9357152 rs9469341  \\\n","0       C:C      G:T       A:G       A:A       A:C       A:A       A:G   \n","1       C:C      G:T       G:G       A:A       C:C       A:G       A:G   \n","2       C:C      T:T       A:A       G:G       C:C       A:A       G:G   \n","\n","  rs9585056  \n","0       T:T  \n","1       C:T  \n","2       C:T  \n","\n","[3 rows x 76 columns]"],"text/html":["\n","  <div id=\"df-742ab7cd-638e-40b9-a021-ab7842514613\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>FID</th>\n","      <th>contact key</th>\n","      <th>rs1049225</th>\n","      <th>rs1052553</th>\n","      <th>rs10795791</th>\n","      <th>rs11203203</th>\n","      <th>rs113010081</th>\n","      <th>rs1150743</th>\n","      <th>rs12416116</th>\n","      <th>rs12720356</th>\n","      <th>...</th>\n","      <th>rs757411</th>\n","      <th>rs7745656</th>\n","      <th>rs7780389</th>\n","      <th>rs917911</th>\n","      <th>rs9268633</th>\n","      <th>rs9271366</th>\n","      <th>rs9273363</th>\n","      <th>rs9357152</th>\n","      <th>rs9469341</th>\n","      <th>rs9585056</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10011708520314</td>\n","      <td>CONTACT10085</td>\n","      <td>C:C</td>\n","      <td>A:A</td>\n","      <td>A:G</td>\n","      <td>A:G</td>\n","      <td>T:T</td>\n","      <td>A:G</td>\n","      <td>C:C</td>\n","      <td>T:T</td>\n","      <td>...</td>\n","      <td>C:T</td>\n","      <td>G:T</td>\n","      <td>C:C</td>\n","      <td>G:T</td>\n","      <td>A:G</td>\n","      <td>A:A</td>\n","      <td>A:C</td>\n","      <td>A:A</td>\n","      <td>A:G</td>\n","      <td>T:T</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10021708520764</td>\n","      <td>CONTACT14053</td>\n","      <td>C:C</td>\n","      <td>A:A</td>\n","      <td>G:G</td>\n","      <td>A:A</td>\n","      <td>T:T</td>\n","      <td>G:G</td>\n","      <td>C:C</td>\n","      <td>T:T</td>\n","      <td>...</td>\n","      <td>C:C</td>\n","      <td>T:T</td>\n","      <td>C:C</td>\n","      <td>G:T</td>\n","      <td>G:G</td>\n","      <td>A:A</td>\n","      <td>C:C</td>\n","      <td>A:G</td>\n","      <td>A:G</td>\n","      <td>C:T</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10021708521587</td>\n","      <td>CONTACT11350</td>\n","      <td>C:C</td>\n","      <td>A:G</td>\n","      <td>A:G</td>\n","      <td>G:G</td>\n","      <td>T:T</td>\n","      <td>A:A</td>\n","      <td>A:A</td>\n","      <td>T:T</td>\n","      <td>...</td>\n","      <td>C:T</td>\n","      <td>T:T</td>\n","      <td>C:C</td>\n","      <td>T:T</td>\n","      <td>A:A</td>\n","      <td>G:G</td>\n","      <td>C:C</td>\n","      <td>A:A</td>\n","      <td>G:G</td>\n","      <td>C:T</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3 rows √ó 76 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-742ab7cd-638e-40b9-a021-ab7842514613')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-742ab7cd-638e-40b9-a021-ab7842514613 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-742ab7cd-638e-40b9-a021-ab7842514613');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe"}},"metadata":{}}],"source":["# 1. Importaci√≥n autom√°tica + conversi√≥n a CSV\n","# Objetivo: traer los datos de forma reproducible (sin subida manual) y dejarlos en CSV para Pig/Spark/Hive.\n","\n","import os, shutil\n","import pandas as pd\n","\n","# 1) Importaci√≥n autom√°tica: clonar repo\n","!rm -rf BDA_dataset\n","!git clone https://github.com/kachytronico/BDA_dataset\n","\n","# 2) Rutas reales a los XLSX dentro del repo clonado\n","base_path = \"/content/BDA_dataset/Dataset not incorporated into the T1DKP\"\n","survey_xlsx = os.path.join(base_path, \"survey_data_and_results_final.xlsx\")\n","geno_xlsx   = os.path.join(base_path, \"assay_final_genotyping_file.xlsx\")\n","\n","assert os.path.exists(survey_xlsx), f\"Falta archivo requerido: {survey_xlsx}\"\n","assert os.path.exists(geno_xlsx),   f\"Falta archivo requerido: {geno_xlsx}\"\n","\n","# 3) Copia a RAW (mantener originales intactos)\n","raw_dir = \"/content/data/raw\"\n","csv_dir = \"/content/data/csv\"\n","os.makedirs(raw_dir, exist_ok=True)\n","os.makedirs(csv_dir, exist_ok=True)\n","\n","survey_raw = os.path.join(raw_dir, \"survey_data_and_results_final.xlsx\")\n","geno_raw   = os.path.join(raw_dir, \"assay_final_genotyping_file.xlsx\")\n","shutil.copy2(survey_xlsx, survey_raw)\n","shutil.copy2(geno_xlsx, geno_raw)\n","\n","# 4) Convertir a CSV (formato base para Pig/Spark/Hive)\n","df_survey = pd.read_excel(survey_raw)\n","df_geno   = pd.read_excel(geno_raw)\n","\n","survey_csv = os.path.join(csv_dir, \"survey.csv\")\n","geno_csv   = os.path.join(csv_dir, \"genotyping.csv\")\n","df_survey.to_csv(survey_csv, index=False)\n","df_geno.to_csv(geno_csv, index=False)\n","\n","# 5) Evidencia m√≠nima visible\n","print(\"üìÅ Repo clonado (muestra):\")\n","!ls -lh BDA_dataset | head -n 20\n","\n","print(\"\\nüìÅ RAW:\")\n","!ls -lh /content/data/raw\n","\n","print(\"\\nüìÅ CSV:\")\n","!ls -lh /content/data/csv\n","\n","print(\"\\nshape survey:\", df_survey.shape)\n","print(\"shape genotyping:\", df_geno.shape)\n","\n","print(\"\\nPreview survey (3 filas):\")\n","display(df_survey.head(3))\n","\n","print(\"\\nPreview genotyping (3 filas):\")\n","display(df_geno.head(3))\n"]},{"cell_type":"markdown","id":"eC9xOD1KN9kS","metadata":{"id":"eC9xOD1KN9kS"},"source":["## Conclusiones (Apartado 1)\n","- He importado los datos de forma autom√°tica clonando el repositorio con `git clone`, sin subida manual.\n","- He conservado los originales en RAW (295 KB survey y 1.4 MB genotyping) y he convertido ambos a CSV (528 KB y 1.2 MB) para poder trabajar despu√©s con Pig y Spark/Hive.\n","- He verificado que ambos datasets tienen **3818 filas**; la estructura final es **15 columnas** en survey y **76 columnas** en genotyping.\n"]},{"cell_type":"markdown","id":"GNB32bF6xgWz","metadata":{"id":"GNB32bF6xgWz"},"source":["# 2. Exploraci√≥n con Pandas (usando CSV convertidos)\n","\n","\n","\n","> Objetivo: validar JOIN real y detectar problemas de calidad (nulos, -9) sobre los CSV.\n","\n"]},{"cell_type":"code","execution_count":2,"id":"kIpv02eiDphS","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1077},"collapsed":true,"executionInfo":{"elapsed":160,"status":"ok","timestamp":1771487317459,"user":{"displayName":"Alfredo Ledesma Ruiz","userId":"02263706330541384863"},"user_tz":-60},"id":"kIpv02eiDphS","outputId":"6f77fe20-0956-4691-b9e7-44053beb9e9d"},"outputs":[{"output_type":"stream","name":"stdout","text":["IDs √∫nicos survey (SUBJECT_ID): 3818\n","IDs √∫nicos genotyping (FID):   3818\n","Intersecci√≥n IDs: 3818\n","Filas merge inner: 3818\n"]},{"output_type":"display_data","data":{"text/plain":["       SUBJECT_ID             FID\n","0  10011708520314  10011708520314\n","1  10021708520764  10021708520764\n","2  10021708521587  10021708521587"],"text/html":["\n","  <div id=\"df-4ecb2add-0ef2-4ee7-a620-1d9e41f5f50a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SUBJECT_ID</th>\n","      <th>FID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10011708520314</td>\n","      <td>10011708520314</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10021708520764</td>\n","      <td>10021708520764</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10021708521587</td>\n","      <td>10021708521587</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ecb2add-0ef2-4ee7-a620-1d9e41f5f50a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-4ecb2add-0ef2-4ee7-a620-1d9e41f5f50a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-4ecb2add-0ef2-4ee7-a620-1d9e41f5f50a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"print(\\\"\\\\nTotal de valores '-9' (string) en genotyping:\\\", int(minus9_total))\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"SUBJECT_ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"10011708520314\",\n          \"10021708520764\",\n          \"10021708521587\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"10011708520314\",\n          \"10021708520764\",\n          \"10021708521587\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Nulos en survey (top 10 columnas):\n"]},{"output_type":"display_data","data":{"text/plain":["SUBJECT_ID          0\n","AGE                 0\n","RACE                0\n","T1D_HIST            0\n","AUTO_HIST           0\n","AUTO_COND           0\n","AUTO_COND_4_TEXT    0\n","T1D_DIAG            0\n","T1D_DIAG_AGE        0\n","T1D_HOSP            0\n","dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>SUBJECT_ID</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>AGE</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>RACE</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>T1D_HIST</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>AUTO_HIST</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>AUTO_COND</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>AUTO_COND_4_TEXT</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>T1D_DIAG</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>T1D_DIAG_AGE</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>T1D_HOSP</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Nulos en genotyping (top 10 columnas):\n"]},{"output_type":"display_data","data":{"text/plain":["FID            0\n","contact key    0\n","rs1049225      0\n","rs1052553      0\n","rs10795791     0\n","rs11203203     0\n","rs113010081    0\n","rs1150743      0\n","rs12416116     0\n","rs12720356     0\n","dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>FID</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>contact key</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>rs1049225</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>rs1052553</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>rs10795791</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>rs11203203</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>rs113010081</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>rs1150743</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>rs12416116</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>rs12720356</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Total de valores '-9' (string) en genotyping: 181\n"]}],"source":["# 2. Exploraci√≥n con Pandas (usando CSV convertidos)\n","# Objetivo: validar JOIN real y detectar problemas de calidad (nulos, -9) sobre los CSV.\n","\n","import pandas as pd\n","\n","survey_csv = \"/content/data/csv/survey.csv\"\n","geno_csv   = \"/content/data/csv/genotyping.csv\"\n","\n","# 1) Cargar CSV forzando texto para evitar problemas de tipos\n","df_s = pd.read_csv(survey_csv, dtype=str)\n","df_g = pd.read_csv(geno_csv, dtype=str)\n","\n","# 2) Confirmaci√≥n de columnas clave\n","assert \"SUBJECT_ID\" in df_s.columns, \"No existe SUBJECT_ID en survey\"\n","assert \"FID\" in df_g.columns, \"No existe FID en genotyping\"\n","\n","# 3) Validaci√≥n JOIN real: survey.SUBJECT_ID = genotyping.FID\n","ids_s = df_s[\"SUBJECT_ID\"].dropna().astype(str).str.strip()\n","ids_g = df_g[\"FID\"].dropna().astype(str).str.strip()\n","\n","print(\"IDs √∫nicos survey (SUBJECT_ID):\", ids_s.nunique())\n","print(\"IDs √∫nicos genotyping (FID):  \", ids_g.nunique())\n","print(\"Intersecci√≥n IDs:\", len(set(ids_s).intersection(set(ids_g))))\n","\n","m = pd.merge(\n","    df_s[[\"SUBJECT_ID\"]],\n","    df_g[[\"FID\"]],\n","    left_on=\"SUBJECT_ID\",\n","    right_on=\"FID\",\n","    how=\"inner\"\n",")\n","\n","print(\"Filas merge inner:\", m.shape[0])\n","display(m.head(3))\n","\n","# 4) Detecci√≥n de nulos / vac√≠os (top 10 columnas)\n","print(\"\\nNulos en survey (top 10 columnas):\")\n","display(df_s.isna().sum().sort_values(ascending=False).head(10))\n","\n","print(\"\\nNulos en genotyping (top 10 columnas):\")\n","display(df_g.isna().sum().sort_values(ascending=False).head(10))\n","\n","# 5) Conteo de '-9' como missing codificado en genotyping\n","minus9_total = (df_g == \"-9\").sum().sum()\n","print(\"\\nTotal de valores '-9' (string) en genotyping:\", int(minus9_total))\n"]},{"cell_type":"markdown","id":"zdtjMapxOI2T","metadata":{"id":"zdtjMapxOI2T"},"source":["## Conclusiones ( Pandas)\n","- He confirmado que hay **3818 IDs √∫nicos** en ambos archivos.\n","- La intersecci√≥n de identificadores es total (**3818 IDs comunes**) y el `merge inner` devuelve **3818 filas**, validando la clave de uni√≥n **`survey.SUBJECT_ID = genotyping.FID`**.\n","- En el top 10 de columnas revisadas no he detectado valores nulos (`NaN`).\n"]},{"cell_type":"markdown","id":"VmrGZiCrzxpd","metadata":{"id":"VmrGZiCrzxpd"},"source":["## Localizar exactamente d√≥nde est√° el missing codificado (-9)\n","\n","\n","> Objetivo: identificar qu√© columnas concretas contienen '-9' para justificar la limpieza en Pig.\n","\n","\n"]},{"cell_type":"code","execution_count":3,"id":"_N4TZAQ4F2Ay","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"collapsed":true,"executionInfo":{"elapsed":94,"status":"ok","timestamp":1771487317559,"user":{"displayName":"Alfredo Ledesma Ruiz","userId":"02263706330541384863"},"user_tz":-60},"id":"_N4TZAQ4F2Ay","outputId":"a16f78fa-1f7b-4e06-e2cc-c94268910e55"},"outputs":[{"output_type":"stream","name":"stdout","text":["Columnas con '-9' (missing codificado) en genotyping:\n"]},{"output_type":"display_data","data":{"text/plain":["rs9585056     89\n","rs12927355    82\n","rs1367728      9\n","rs72727394     1\n","dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>rs9585056</th>\n","      <td>89</td>\n","    </tr>\n","    <tr>\n","      <th>rs12927355</th>\n","      <td>82</td>\n","    </tr>\n","    <tr>\n","      <th>rs1367728</th>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>rs72727394</th>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Total '-9' en genotyping: 181\n","\n","Columnas con cadenas vac√≠as '' en survey:\n"]},{"output_type":"display_data","data":{"text/plain":["Series([], dtype: int64)"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{}}],"source":["# Localizar exactamente d√≥nde est√° el missing codificado (-9)\n","# Objetivo: identificar qu√© columnas concretas contienen '-9' para justificar la limpieza en Pig.\n","\n","import pandas as pd\n","\n","survey_csv = \"/content/data/csv/survey.csv\"\n","geno_csv   = \"/content/data/csv/genotyping.csv\"\n","\n","df_s = pd.read_csv(survey_csv, dtype=str)\n","df_g = pd.read_csv(geno_csv, dtype=str)\n","\n","# 1) Conteo por columna de '-9' en genotyping (missing codificado)\n","minus9_by_column = (df_g == \"-9\").sum()\n","minus9_by_column = minus9_by_column[minus9_by_column > 0].sort_values(ascending=False)\n","\n","print(\"Columnas con '-9' (missing codificado) en genotyping:\")\n","display(minus9_by_column)\n","\n","print(\"\\nTotal '-9' en genotyping:\", int((df_g == \"-9\").sum().sum()))\n","\n","# 2) Comprobaci√≥n de cadenas vac√≠as en survey (por si hubiese valores \"\" en vez de NaN)\n","empty_strings_survey = (df_s == \"\").sum()\n","empty_strings_survey = empty_strings_survey[empty_strings_survey > 0]\n","\n","print(\"\\nColumnas con cadenas vac√≠as '' en survey:\")\n","display(empty_strings_survey)\n"]},{"cell_type":"markdown","id":"Ol67aeHXOREk","metadata":{"id":"Ol67aeHXOREk"},"source":["## Conclusiones (calidad de datos)\n","- He detectado un total de **181 valores `\"-9\"`** en la tabla genotyping (missing codificado).\n","- El desglose es: `rs9585056` (89), `rs12927355` (82), `rs1367728` (9) y `rs72727394` (1).\n","- He comprobado que no existen cadenas vac√≠as (`\"\"`) en la tabla survey.\n","- En el siguiente apartado limpiar√© estos `\"-9\"` convirti√©ndolos a valores nulos reales para no distorsionar transformaciones y consultas.\n"]},{"cell_type":"markdown","id":"0decad02","metadata":{"id":"0decad02"},"source":["# 3) Apache Pig ‚Äî Limpieza + tratamiento\n","En esta secci√≥n voy a preparar Pig para limpiar datos de genotyping y normalizar claves para asegurar un JOIN fiable.\n","Primero dejar√© el entorno listo en Colab con Java 17 y Pig, siguiendo el estilo de los cuadernos de referencia.\n","Como tratamiento interesante simple, usar√© un Top 3 de valores m√°s frecuentes en una columna clave tras la limpieza."]},{"cell_type":"code","execution_count":4,"id":"b23bd4e2","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":82943,"status":"ok","timestamp":1771487400506,"user":{"displayName":"Alfredo Ledesma Ruiz","userId":"02263706330541384863"},"user_tz":-60},"id":"b23bd4e2","outputId":"679400e2-5289-41cb-b833-f58e034ca13f"},"outputs":[{"output_type":"stream","name":"stdout","text":["openjdk version \"17.0.17\" 2025-10-21\n","OpenJDK Runtime Environment (build 17.0.17+10-Ubuntu-122.04)\n","OpenJDK 64-Bit Server VM (build 17.0.17+10-Ubuntu-122.04, mixed mode, sharing)\n","Hadoop 3.4.2\n","Source code repository https://github.com/apache/hadoop.git -r 84e8b89ee2ebe6923691205b9e171badde7a495c\n","Compiled by ahmarsu on 2025-08-20T10:30Z\n","Apache Pig version 0.17.0 (r1797386) \n","compiled Jun 02 2017, 15:41:58\n"]}],"source":["# Secci√≥n 3.1 ‚Äî Preparaci√≥n de entorno Pig en Colab (Java 17)\n","# Estilo base: cuaderno 0301 (instalaci√≥n simple y verificaci√≥n de versi√≥n)\n","\n","import os\n","\n","# 1) Java 17\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-17-openjdk-amd64\"\n","\n","# 2) Hadoop (dependencia de entorno para Pig)\n","!wget -q https://downloads.apache.org/hadoop/common/hadoop-3.4.2/hadoop-3.4.2.tar.gz\n","!tar -xzf hadoop-3.4.2.tar.gz\n","!rm -rf /usr/local/hadoop\n","!mv hadoop-3.4.2 /usr/local/hadoop\n","\n","os.environ[\"HADOOP_HOME\"] = \"/usr/local/hadoop\"\n","os.environ[\"PATH\"] += f\":{os.environ['HADOOP_HOME']}/bin:{os.environ['HADOOP_HOME']}/sbin\"\n","\n","# 3) Pig\n","!wget -q https://downloads.apache.org/pig/pig-0.17.0/pig-0.17.0.tar.gz\n","!tar -xzf pig-0.17.0.tar.gz\n","!rm -rf /usr/local/pig-0.17.0\n","!mv pig-0.17.0 /usr/local/pig-0.17.0\n","\n","os.environ[\"PIG_HOME\"] = \"/usr/local/pig-0.17.0\"\n","os.environ[\"PATH\"] += f\":{os.environ['PIG_HOME']}/bin\"\n","os.environ[\"PIG_CLASSPATH\"] = \"/usr/local/hadoop/etc/hadoop\"\n","\n","# 4) Verificaci√≥n m√≠nima visible\n","!java -version\n","!hadoop version | head -n 3\n","!pig -version"]},{"cell_type":"code","execution_count":5,"id":"4e70955a","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1771487400523,"user":{"displayName":"Alfredo Ledesma Ruiz","userId":"02263706330541384863"},"user_tz":-60},"id":"4e70955a","outputId":"12dd86c6-2526-443f-8b09-89c9f9c605be"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing limpieza.pig\n"]}],"source":["%%writefile limpieza.pig\n","-- Secci√≥n 3.1: limpieza de survey y genotyping\n","\n","survey_raw = LOAD '/content/data/csv/survey.csv' USING PigStorage(',') AS (\n","    SUBJECT_ID:chararray,\n","    AGE:chararray,\n","    RACE:chararray,\n","    T1D_HIST:chararray,\n","    AUTO_HIST:chararray,\n","    AUTO_COND:chararray,\n","    AUTO_COND_4_TEXT:chararray,\n","    T1D_DIAG:chararray,\n","    T1D_DIAG_AGE:chararray,\n","    T1D_HOSP:chararray,\n","    DKA:chararray,\n","    GRS_HLA:chararray,\n","    GnonHLA:chararray,\n","    GRS:chararray,\n","    Risk:chararray\n",");\n","\n","survey_no_header = FILTER survey_raw BY SUBJECT_ID != 'SUBJECT_ID';\n","\n","survey_clean = FOREACH survey_no_header GENERATE\n","    TRIM(SUBJECT_ID) AS SUBJECT_ID,\n","    AGE,\n","    RACE,\n","    T1D_HIST,\n","    AUTO_HIST,\n","    AUTO_COND,\n","    AUTO_COND_4_TEXT,\n","    T1D_DIAG,\n","    T1D_DIAG_AGE,\n","    T1D_HOSP,\n","    DKA,\n","    GRS_HLA,\n","    GnonHLA,\n","    GRS,\n","    Risk;\n","\n","STORE survey_clean INTO '/content/data/pig_out/survey_clean' USING PigStorage(',');\n","\n","\n","genotyping_raw = LOAD '/content/data/csv/genotyping.csv' USING PigStorage(',') AS (\n","    FID:chararray,\n","    contact_key:chararray,\n","    rs1049225:chararray,\n","    rs1052553:chararray,\n","    rs10795791:chararray,\n","    rs11203203:chararray,\n","    rs113010081:chararray,\n","    rs1150743:chararray,\n","    rs12416116:chararray,\n","    rs12720356:chararray,\n","    rs12927355:chararray,\n","    rs12971201:chararray,\n","    rs13415583:chararray,\n","    rs1367728:chararray,\n","    rs1456988:chararray,\n","    rs151233:chararray,\n","    rs1574285:chararray,\n","    rs1615504:chararray,\n","    rs1893217:chararray,\n","    rs193778:chararray,\n","    rs2045258:chararray,\n","    rs2071463:chararray,\n","    rs2076531:chararray,\n","    rs2111485:chararray,\n","    rs2143461:chararray,\n","    rs2194225:chararray,\n","    rs2239800:chararray,\n","    rs2256974:chararray,\n","    rs229533:chararray,\n","    rs2476601:chararray,\n","    rs2523409:chararray,\n","    rs2524089:chararray,\n","    rs2611215:chararray,\n","    rs28732101:chararray,\n","    rs3024505:chararray,\n","    rs3087243:chararray,\n","    rs3094165:chararray,\n","    rs3129722:chararray,\n","    rs3130933:chararray,\n","    rs34536443:chararray,\n","    rs34593439:chararray,\n","    rs35337543:chararray,\n","    rs35667974:chararray,\n","    rs3763305:chararray,\n","    rs402072:chararray,\n","    rs41295121:chararray,\n","    rs436845:chararray,\n","    rs4820830:chararray,\n","    rs4849135:chararray,\n","    rs516246:chararray,\n","    rs56994090:chararray,\n","    rs6043409:chararray,\n","    rs61839660:chararray,\n","    rs62447205:chararray,\n","    rs635688:chararray,\n","    rs6518350:chararray,\n","    rs653178:chararray,\n","    rs6691977:chararray,\n","    rs689:chararray,\n","    rs6903608:chararray,\n","    rs6906897:chararray,\n","    rs6935715:chararray,\n","    rs705704:chararray,\n","    rs72727394:chararray,\n","    rs72853903:chararray,\n","    rs72928038:chararray,\n","    rs757411:chararray,\n","    rs7745656:chararray,\n","    rs7780389:chararray,\n","    rs917911:chararray,\n","    rs9268633:chararray,\n","    rs9271366:chararray,\n","    rs9273363:chararray,\n","    rs9357152:chararray,\n","    rs9469341:chararray,\n","    rs9585056:chararray\n",");\n","\n","genotyping_no_header = FILTER genotyping_raw BY FID != 'FID';\n","\n","genotyping_clean = FOREACH genotyping_no_header GENERATE\n","    TRIM(FID) AS FID,\n","    contact_key,\n","    rs1049225,\n","    rs1052553,\n","    rs10795791,\n","    rs11203203,\n","    rs113010081,\n","    rs1150743,\n","    rs12416116,\n","    rs12720356,\n","    (rs12927355 == '-9' ? '' : rs12927355) AS rs12927355,\n","    rs12971201,\n","    rs13415583,\n","    (rs1367728 == '-9' ? '' : rs1367728) AS rs1367728,\n","    rs1456988,\n","    rs151233,\n","    rs1574285,\n","    rs1615504,\n","    rs1893217,\n","    rs193778,\n","    rs2045258,\n","    rs2071463,\n","    rs2076531,\n","    rs2111485,\n","    rs2143461,\n","    rs2194225,\n","    rs2239800,\n","    rs2256974,\n","    rs229533,\n","    rs2476601,\n","    rs2523409,\n","    rs2524089,\n","    rs2611215,\n","    rs28732101,\n","    rs3024505,\n","    rs3087243,\n","    rs3094165,\n","    rs3129722,\n","    rs3130933,\n","    rs34536443,\n","    rs34593439,\n","    rs35337543,\n","    rs35667974,\n","    rs3763305,\n","    rs402072,\n","    rs41295121,\n","    rs436845,\n","    rs4820830,\n","    rs4849135,\n","    rs516246,\n","    rs56994090,\n","    rs6043409,\n","    rs61839660,\n","    rs62447205,\n","    rs635688,\n","    rs6518350,\n","    rs653178,\n","    rs6691977,\n","    rs689,\n","    rs6903608,\n","    rs6906897,\n","    rs6935715,\n","    rs705704,\n","    (rs72727394 == '-9' ? '' : rs72727394) AS rs72727394,\n","    rs72853903,\n","    rs72928038,\n","    rs757411,\n","    rs7745656,\n","    rs7780389,\n","    rs917911,\n","    rs9268633,\n","    rs9271366,\n","    rs9273363,\n","    rs9357152,\n","    rs9469341,\n","    (rs9585056 == '-9' ? '' : rs9585056) AS rs9585056;\n","\n","STORE genotyping_clean INTO '/content/data/pig_out/genotyping_clean' USING PigStorage(',');"]},{"cell_type":"code","execution_count":6,"id":"df083b23","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":8831,"status":"ok","timestamp":1771487409355,"user":{"displayName":"Alfredo Ledesma Ruiz","userId":"02263706330541384863"},"user_tz":-60},"id":"df083b23","outputId":"f7d97879-bf1c-48b8-8064-a8e8698a6761"},"outputs":[{"output_type":"stream","name":"stdout","text":["2026-02-19 07:50:03,209 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL\n","2026-02-19 07:50:03,210 INFO pig.ExecTypeProvider: Picked LOCAL as the ExecType\n","2026-02-19 07:50:03,330 [main] INFO  org.apache.pig.Main - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58\n","2026-02-19 07:50:03,330 [main] INFO  org.apache.pig.Main - Logging error messages to: /content/pig_1771487403327.log\n","2026-02-19 07:50:03,361 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - user.name is deprecated. Instead, use mapreduce.job.user.name\n","2026-02-19 07:50:03,655 [main] INFO  org.apache.pig.impl.util.Utils - Default bootup file /root/.pigbootup not found\n","2026-02-19 07:50:03,784 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n","2026-02-19 07:50:03,787 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: file:///\n","2026-02-19 07:50:03,826 [main] INFO  org.apache.pig.PigServer - Pig Script ID for the session: PIG-limpieza.pig-9165656a-4df5-464f-bd65-21a8ded013cd\n","2026-02-19 07:50:03,826 [main] WARN  org.apache.pig.PigServer - ATS is disabled since yarn.timeline-service.enabled set to false\n","2026-02-19 07:50:04,675 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n","2026-02-19 07:50:04,718 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: FILTER\n","2026-02-19 07:50:04,814 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n","2026-02-19 07:50:04,926 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (G1 Old Gen) of size 1048576000 to monitor. collectionUsageThreshold = 734003200, usageThreshold = 734003200\n","2026-02-19 07:50:05,037 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler - File concatenation threshold: 100 optimistic? false\n","2026-02-19 07:50:05,074 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size before optimization: 2\n","2026-02-19 07:50:05,074 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size after optimization: 2\n","2026-02-19 07:50:05,503 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n","2026-02-19 07:50:05,514 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n","2026-02-19 07:50:05,514 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n","2026-02-19 07:50:05,517 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n","2026-02-19 07:50:05,549 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n","2026-02-19 07:50:05,565 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Key [pig.schematuple] is false, will not generate code.\n","2026-02-19 07:50:05,566 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Starting process to move generated code to distributed cacche\n","2026-02-19 07:50:05,566 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Distributed cache not supported or needed in local mode. Setting key [pig.schematuple.local.dir] with code temp directory: /tmp/1771487405565-0\n","2026-02-19 07:50:05,692 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n","2026-02-19 07:50:05,695 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n","2026-02-19 07:50:05,702 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n","2026-02-19 07:50:05,705 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Key [pig.schematuple] is false, will not generate code.\n","2026-02-19 07:50:05,705 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Starting process to move generated code to distributed cacche\n","2026-02-19 07:50:05,705 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Distributed cache not supported or needed in local mode. Setting key [pig.schematuple.local.dir] with code temp directory: /tmp/1771487405705-0\n","2026-02-19 07:50:05,803 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 2 map-reduce job(s) waiting for submission.\n","2026-02-19 07:50:05,817 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 07:50:05,838 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n","2026-02-19 07:50:05,999 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n","2026-02-19 07:50:06,024 [JobControl] INFO  org.apache.pig.builtin.PigStorage - Using PigTextInputFormat\n","2026-02-19 07:50:06,058 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n","2026-02-19 07:50:06,058 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n","2026-02-19 07:50:06,101 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n","2026-02-19 07:50:06,197 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n","2026-02-19 07:50:06,601 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1245037451_0001\n","2026-02-19 07:50:06,603 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n","2026-02-19 07:50:06,929 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n","2026-02-19 07:50:06,930 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 07:50:06,931 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n","2026-02-19 07:50:06,958 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n","2026-02-19 07:50:06,960 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n","2026-02-19 07:50:06,963 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n","2026-02-19 07:50:06,968 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n","2026-02-19 07:50:06,976 [JobControl] INFO  org.apache.pig.builtin.PigStorage - Using PigTextInputFormat\n","2026-02-19 07:50:06,980 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n","2026-02-19 07:50:06,981 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n","2026-02-19 07:50:06,982 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n","2026-02-19 07:50:06,994 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n","2026-02-19 07:50:07,010 [Thread-5] INFO  org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory - No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2026-02-19 07:50:07,014 [Thread-5] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n","2026-02-19 07:50:07,016 [Thread-5] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2026-02-19 07:50:07,018 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n","2026-02-19 07:50:07,067 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1389053344_0002\n","2026-02-19 07:50:07,067 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n","2026-02-19 07:50:07,162 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n","2026-02-19 07:50:07,163 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1245037451_0001_m_000000_0\n","2026-02-19 07:50:07,271 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n","2026-02-19 07:50:07,279 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory - No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2026-02-19 07:50:07,279 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n","2026-02-19 07:50:07,279 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2026-02-19 07:50:07,338 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n","2026-02-19 07:50:07,339 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n","2026-02-19 07:50:07,340 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n","2026-02-19 07:50:07,358 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n","Total Length = 539738\n","Input split[0]:\n","   Length = 539738\n","   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n","   Locations:\n","\n","-----------------------\n","\n","2026-02-19 07:50:07,431 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n","2026-02-19 07:50:07,433 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n","2026-02-19 07:50:07,433 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory - No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2026-02-19 07:50:07,433 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n","2026-02-19 07:50:07,433 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2026-02-19 07:50:07,434 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n","2026-02-19 07:50:07,438 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.builtin.PigStorage - Using PigTextInputFormat\n","2026-02-19 07:50:07,445 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/content/data/csv/survey.csv:0+539738\n","2026-02-19 07:50:07,456 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1389053344_0002_m_000000_0\n","2026-02-19 07:50:07,457 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n","2026-02-19 07:50:07,463 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory - No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2026-02-19 07:50:07,463 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n","2026-02-19 07:50:07,463 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2026-02-19 07:50:07,488 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (G1 Old Gen) of size 1048576000 to monitor. collectionUsageThreshold = 734003200, usageThreshold = 734003200\n","2026-02-19 07:50:07,492 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.data.SchemaTupleBackend - Key [pig.schematuple] was not set... will not generate code.\n","2026-02-19 07:50:07,493 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory - No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2026-02-19 07:50:07,493 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n","2026-02-19 07:50:07,494 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2026-02-19 07:50:07,504 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n","2026-02-19 07:50:07,510 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n","Total Length = 1243581\n","Input split[0]:\n","   Length = 1243581\n","   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n","   Locations:\n","\n","-----------------------\n","\n","2026-02-19 07:50:07,520 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapOnly$Map - Aliases being processed per job phase (AliasName[line,offset]): M: survey_raw[3,13],survey_raw[-1,-1],survey_no_header[21,19],survey_clean[23,15] C:  R: \n","2026-02-19 07:50:07,522 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.builtin.PigStorage - Using PigTextInputFormat\n","2026-02-19 07:50:07,525 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/content/data/csv/genotyping.csv:0+1243581\n","2026-02-19 07:50:07,542 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory - No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2026-02-19 07:50:07,544 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n","2026-02-19 07:50:07,544 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2026-02-19 07:50:07,565 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (G1 Old Gen) of size 1048576000 to monitor. collectionUsageThreshold = 734003200, usageThreshold = 734003200\n","2026-02-19 07:50:07,566 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n","2026-02-19 07:50:07,655 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapOnly$Map - Aliases being processed per job phase (AliasName[line,offset]): M: genotyping_raw[43,17],genotyping_raw[-1,-1],genotyping_no_header[122,23],genotyping_clean[124,19] C:  R: \n","2026-02-19 07:50:07,841 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1245037451_0001\n","2026-02-19 07:50:07,841 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases survey_clean,survey_no_header,survey_raw\n","2026-02-19 07:50:07,841 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: survey_raw[3,13],survey_raw[-1,-1],survey_no_header[21,19],survey_clean[23,15] C:  R: \n","2026-02-19 07:50:07,848 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1389053344_0002\n","2026-02-19 07:50:07,848 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases genotyping_clean,genotyping_no_header,genotyping_raw\n","2026-02-19 07:50:07,849 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: genotyping_raw[43,17],genotyping_raw[-1,-1],genotyping_no_header[122,23],genotyping_clean[124,19] C:  R: \n","2026-02-19 07:50:07,861 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 0% complete\n","2026-02-19 07:50:07,862 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1245037451_0001,job_local1389053344_0002]\n","2026-02-19 07:50:08,069 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n","2026-02-19 07:50:08,087 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1245037451_0001_m_000000_0 is done. And is in the process of committing\n","2026-02-19 07:50:08,111 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n","2026-02-19 07:50:08,111 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1245037451_0001_m_000000_0 is allowed to commit now\n","2026-02-19 07:50:08,131 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1245037451_0001_m_000000_0' to file:/content/data/pig_out/survey_clean\n","2026-02-19 07:50:08,138 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n","2026-02-19 07:50:08,139 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1245037451_0001_m_000000_0' done.\n","2026-02-19 07:50:08,157 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1245037451_0001_m_000000_0: Counters: 15\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=905120\n","\t\tFILE: Number of bytes written=2271220\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tMap input records=3819\n","\t\tMap output records=3818\n","\t\tInput split bytes=360\n","\t\tSpilled Records=0\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=0\n","\t\tGC time elapsed (ms)=66\n","\t\tTotal committed heap usage (bytes)=125829120\n","\tFile Input Format Counters \n","\t\tBytes Read=0\n","\tFile Output Format Counters \n","\t\tBytes Written=0\n","2026-02-19 07:50:08,160 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1245037451_0001_m_000000_0\n","2026-02-19 07:50:08,162 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n","2026-02-19 07:50:08,366 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 50% complete\n","2026-02-19 07:50:08,366 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1389053344_0002]\n","2026-02-19 07:50:08,380 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 07:50:08,410 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 07:50:08,412 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n","2026-02-19 07:50:08,412 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n","2026-02-19 07:50:08,415 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 07:50:08,627 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n","2026-02-19 07:50:08,628 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1389053344_0002_m_000000_0 is done. And is in the process of committing\n","2026-02-19 07:50:08,637 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n","2026-02-19 07:50:08,637 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1389053344_0002_m_000000_0 is allowed to commit now\n","2026-02-19 07:50:08,651 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1389053344_0002_m_000000_0' to file:/content/data/pig_out/genotyping_clean\n","2026-02-19 07:50:08,652 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n","2026-02-19 07:50:08,652 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1389053344_0002_m_000000_0' done.\n","2026-02-19 07:50:08,653 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1389053344_0002_m_000000_0: Counters: 15\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=1784157\n","\t\tFILE: Number of bytes written=3161161\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tMap input records=3819\n","\t\tMap output records=3818\n","\t\tInput split bytes=364\n","\t\tSpilled Records=0\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=0\n","\t\tGC time elapsed (ms)=32\n","\t\tTotal committed heap usage (bytes)=125829120\n","\tFile Input Format Counters \n","\t\tBytes Read=0\n","\tFile Output Format Counters \n","\t\tBytes Written=0\n","2026-02-19 07:50:08,654 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1389053344_0002_m_000000_0\n","2026-02-19 07:50:08,654 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n","2026-02-19 07:50:08,777 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 07:50:08,783 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 07:50:08,786 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 07:50:08,789 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 100% complete\n","2026-02-19 07:50:08,793 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats - Script Statistics: \n","\n","HadoopVersion\tPigVersion\tUserId\tStartedAt\tFinishedAt\tFeatures\n","3.4.2\t0.17.0\troot\t2026-02-19 07:50:05\t2026-02-19 07:50:08\tFILTER\n","\n","Success!\n","\n","Job Stats (time in seconds):\n","JobId\tMaps\tReduces\tMaxMapTime\tMinMapTime\tAvgMapTime\tMedianMapTime\tMaxReduceTime\tMinReduceTime\tAvgReduceTime\tMedianReducetime\tAlias\tFeature\tOutputs\n","job_local1245037451_0001\t1\t0\tn/a\tn/a\tn/a\tn/a\t0\t0\t0\t0\tsurvey_clean,survey_no_header,survey_raw\tMAP_ONLY\t/content/data/pig_out/survey_clean,\n","job_local1389053344_0002\t1\t0\tn/a\tn/a\tn/a\tn/a\t0\t0\t0\t0\tgenotyping_clean,genotyping_no_header,genotyping_raw\tMAP_ONLY\t/content/data/pig_out/genotyping_clean,\n","\n","Input(s):\n","Successfully read 3819 records from: \"/content/data/csv/survey.csv\"\n","Successfully read 3819 records from: \"/content/data/csv/genotyping.csv\"\n","\n","Output(s):\n","Successfully stored 3818 records in: \"/content/data/pig_out/survey_clean\"\n","Successfully stored 3818 records in: \"/content/data/pig_out/genotyping_clean\"\n","\n","Counters:\n","Total records written : 7636\n","Total bytes written : 0\n","Spillable Memory Manager spill count : 0\n","Total bags proactively spilled: 0\n","Total records proactively spilled: 0\n","\n","Job DAG:\n","job_local1245037451_0001\n","job_local1389053344_0002\n","\n","\n","2026-02-19 07:50:08,797 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 07:50:08,800 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 07:50:08,803 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 07:50:08,816 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 07:50:08,820 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 07:50:08,822 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 07:50:08,831 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Success!\n","2026-02-19 07:50:08,870 [main] INFO  org.apache.pig.Main - Pig script completed in 5 seconds and 961 milliseconds (5961 ms)\n","\n","Salida survey_clean:\n","total 524K\n","-rw-r--r-- 1 root root 523K Feb 19 07:50 part-m-00000\n","-rw-r--r-- 1 root root    0 Feb 19 07:50 _SUCCESS\n","Primeras 3 filas survey_clean:\n","10011708520314,6,White,Yes,No,Not applicable,Not applicable,No,Not applicable,Not applicable,Not applicable,1.91,0.14,2.06,Not high\n","10021708520764,3,White,Don't know,Yes,\"Thyroid_Hashimotos and_or Graves, Blood relative has been diagnosed with autoimmune disease but I don't know which condition\",Not applicable,No,Not applicable,Not applicable,Not applicable,-1.41,1.93,0.52\n","10021708521587,7,Asian,Don't know,No,Not applicable,Not applicable,No,Not applicable,Not applicable,Not applicable,-13.66,0.77,-12.89,Not high\n","\n","Salida genotyping_clean:\n","total 1.2M\n","-rw-r--r-- 1 root root 1.2M Feb 19 07:50 part-m-00000\n","-rw-r--r-- 1 root root    0 Feb 19 07:50 _SUCCESS\n","Primeras 3 filas genotyping_clean:\n","10011708520314,CONTACT10085,C:C,A:A,A:G,A:G,T:T,A:G,C:C,T:T,T:C,A:G,G:T,A:G,G:T,A:G,G:G,G:G,T:T,T:T,C:T,G:G,T:T,A:G,C:C,A:A,C:T,T:G,A:A,G:G,C:T,A:A,C:C,C:C,C:C,A:G,C:T,C:C,G:G,G:G,G:G,G:G,A:A,A:G,A:G,C:T,C:T,T:C,G:G,A:G,T:T,A:G,C:C,A:A,C:T,A:A,G:G,T:T,A:A,T:T,C:C,T:T,G:G,C:T,C:T,G:G,C:T,G:T,C:C,G:T,A:G,A:A,A:C,A:A,A:G,T:T\n","10021708520764,CONTACT14053,C:C,A:A,G:G,A:A,T:T,G:G,C:C,T:T,C:C,G:G,T:T,G:G,G:T,G:G,G:T,A:G,C:T,C:T,C:C,A:G,T:T,G:G,C:C,A:G,T:T,G:G,C:C,A:G,C:C,A:C,C:C,C:C,C:T,A:G,C:C,C:C,G:G,G:G,G:G,G:G,A:A,G:G,A:A,C:C,T:T,T:T,G:G,G:G,T:T,A:A,C:C,A:G,T:T,A:A,A:G,T:T,A:T,C:T,C:C,T:T,A:G,C:C,C:C,G:G,C:C,T:T,C:C,G:T,G:G,A:A,C:C,A:G,A:G,C:T\n","10021708521587,CONTACT11350,C:C,A:G,A:G,G:G,T:T,A:A,A:A,T:T,T:T,G:G,T:T,G:G,G:G,A:A,G:T,A:G,T:T,T:T,C:C,A:A,C:C,A:G,C:C,A:A,T:T,G:G,A:C,G:G,T:T,A:A,C:C,C:C,C:C,A:A,T:T,C:C,G:G,G:G,G:G,G:G,A:A,G:G,A:A,C:C,T:T,T:T,T:T,G:G,T:T,A:G,C:C,A:A,C:C,A:A,A:G,C:T,A:A,T:T,C:C,T:T,A:G,C:T,C:C,A:G,C:T,T:T,C:C,T:T,A:A,G:G,C:C,A:A,G:G,C:T\n"]}],"source":["# Ejecutar limpieza Pig en modo local y mostrar evidencias m√≠nimas\n","\n","!rm -rf /content/data/pig_out/survey_clean /content/data/pig_out/genotyping_clean\n","!pig -x local -f limpieza.pig\n","\n","print(\"\\nSalida survey_clean:\")\n","!ls -lh /content/data/pig_out/survey_clean\n","print(\"Primeras 3 filas survey_clean:\")\n","!head -n 3 /content/data/pig_out/survey_clean/part*\n","\n","print(\"\\nSalida genotyping_clean:\")\n","!ls -lh /content/data/pig_out/genotyping_clean\n","print(\"Primeras 3 filas genotyping_clean:\")\n","!head -n 3 /content/data/pig_out/genotyping_clean/part*"]},{"cell_type":"markdown","id":"38a71f32","metadata":{"id":"38a71f32"},"source":["## Conclusiones (Secci√≥n 3.1 ‚Äî Limpieza con Pig)‚Äù\n","\n","He ejecutado limpieza.pig en modo local y la limpieza ha funcionado correctamente. Se han generado las carpetas de salida survey_clean y genotyping_clean dentro de /content/data/pig_out/, cada una con su fichero part-m-00000 y el marcador _SUCCESS. En concreto, survey_clean ocupa aproximadamente 523 KB y genotyping_clean aproximadamente 1.2 MB.\n","\n","\n","Adem√°s, he normalizado las claves de relaci√≥n aplicando TRIM() sobre SUBJECT_ID y FID, dejando los datos preparados para un JOIN posterior fiable. Por √∫ltimo, he aplicado la correcci√≥n del missing codificado sustituyendo '-9' por vac√≠o ('') √∫nicamente en los 4 marcadores identificados previamente (rs9585056, rs12927355, rs1367728 y rs72727394), manteniendo el resto de columnas sin cambios."]},{"cell_type":"markdown","id":"bd39c2f9","metadata":{"id":"bd39c2f9"},"source":["## Secci√≥n 3.2 ‚Äî Tratamiento interesante\n","En este bloque calculo el Top 3 de valores m√°s frecuentes de `RACE` a partir de `survey_clean` con Pig, mostrando el resultado en pantalla con `DUMP`."]},{"cell_type":"code","execution_count":15,"id":"eb48c14a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1771489958127,"user":{"displayName":"Alfredo Ledesma Ruiz","userId":"02263706330541384863"},"user_tz":-60},"id":"eb48c14a","outputId":"047d3534-ac91-4568-f4b4-b13741cfccfa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting tratamiento_top3_race.pig\n"]}],"source":["%%writefile tratamiento_top3_race.pig\n","-- Secci√≥n 3.2: tratamiento interesante simple (Top 3 de RACE)\n","\n","survey_clean = LOAD '/content/data/pig_out/survey_clean' USING PigStorage(',') AS (\n","    SUBJECT_ID:chararray,\n","    AGE:chararray,\n","    RACE:chararray,\n","    T1D_HIST:chararray,\n","    AUTO_HIST:chararray,\n","    AUTO_COND:chararray,\n","    AUTO_COND_4_TEXT:chararray,\n","    T1D_DIAG:chararray,\n","    T1D_DIAG_AGE:chararray,\n","    T1D_HOSP:chararray,\n","    DKA:chararray,\n","    GRS_HLA:chararray,\n","    GnonHLA:chararray,\n","    GRS:chararray,\n","    Risk:chararray\n",");\n","\n","survey_valid = FILTER survey_clean BY (RACE IS NOT NULL) AND (TRIM(RACE) != '');\n","\n","race_group = GROUP survey_valid BY RACE;\n","race_count = FOREACH race_group GENERATE group AS RACE, COUNT(survey_valid) AS total;\n","race_order = ORDER race_count BY $1 DESC;\n","top3_race = LIMIT race_order 3;\n","\n","DUMP top3_race;"]},{"cell_type":"code","execution_count":19,"id":"41d2e791","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9726,"status":"ok","timestamp":1771490583301,"user":{"displayName":"Alfredo Ledesma Ruiz","userId":"02263706330541384863"},"user_tz":-60},"id":"41d2e791","outputId":"5b6a81e9-e7dd-4631-8deb-3d8f25c47480"},"outputs":[{"output_type":"stream","name":"stdout","text":["2026-02-19 08:42:55,707 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL\n","2026-02-19 08:42:55,708 INFO pig.ExecTypeProvider: Picked LOCAL as the ExecType\n","2026-02-19 08:42:55,830 [main] INFO  org.apache.pig.Main - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58\n","2026-02-19 08:42:55,831 [main] INFO  org.apache.pig.Main - Logging error messages to: /content/pig_1771490575827.log\n","2026-02-19 08:42:55,851 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - user.name is deprecated. Instead, use mapreduce.job.user.name\n","2026-02-19 08:42:56,105 [main] INFO  org.apache.pig.impl.util.Utils - Default bootup file /root/.pigbootup not found\n","2026-02-19 08:42:56,224 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n","2026-02-19 08:42:56,227 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: file:///\n","2026-02-19 08:42:56,267 [main] INFO  org.apache.pig.PigServer - Pig Script ID for the session: PIG-tratamiento_top3_race.pig-eabad2c9-fcde-4758-b156-26a4db9b7b2c\n","2026-02-19 08:42:56,267 [main] WARN  org.apache.pig.PigServer - ATS is disabled since yarn.timeline-service.enabled set to false\n","2026-02-19 08:42:56,940 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: GROUP_BY,ORDER_BY,FILTER,LIMIT\n","2026-02-19 08:42:57,040 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n","2026-02-19 08:42:57,131 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (G1 Old Gen) of size 1048576000 to monitor. collectionUsageThreshold = 734003200, usageThreshold = 734003200\n","2026-02-19 08:42:57,191 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler - File concatenation threshold: 100 optimistic? false\n","2026-02-19 08:42:57,218 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil - Choosing to move algebraic foreach to combiner\n","2026-02-19 08:42:57,249 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR - Using Secondary Key Optimization for MapReduce node scope-72\n","2026-02-19 08:42:57,266 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size before optimization: 4\n","2026-02-19 08:42:57,266 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size after optimization: 4\n","2026-02-19 08:42:57,648 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n","2026-02-19 08:42:57,656 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n","2026-02-19 08:42:57,656 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n","2026-02-19 08:42:57,658 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n","2026-02-19 08:42:57,661 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n","2026-02-19 08:42:57,662 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n","2026-02-19 08:42:57,703 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=534792\n","2026-02-19 08:42:57,706 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n","2026-02-19 08:42:57,706 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n","2026-02-19 08:42:57,732 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n","2026-02-19 08:42:57,743 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Key [pig.schematuple] is false, will not generate code.\n","2026-02-19 08:42:57,743 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Starting process to move generated code to distributed cacche\n","2026-02-19 08:42:57,743 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Distributed cache not supported or needed in local mode. Setting key [pig.schematuple.local.dir] with code temp directory: /tmp/1771490577743-0\n","2026-02-19 08:42:57,862 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n","2026-02-19 08:42:57,874 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 08:42:57,890 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n","2026-02-19 08:42:57,982 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n","2026-02-19 08:42:58,024 [JobControl] INFO  org.apache.pig.builtin.PigStorage - Using PigTextInputFormat\n","2026-02-19 08:42:58,042 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n","2026-02-19 08:42:58,042 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n","2026-02-19 08:42:58,056 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n","2026-02-19 08:42:58,141 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n","2026-02-19 08:42:58,466 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1020340557_0001\n","2026-02-19 08:42:58,468 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n","2026-02-19 08:42:58,755 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n","2026-02-19 08:42:58,756 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n","2026-02-19 08:42:58,822 [Thread-5] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n","2026-02-19 08:42:58,826 [Thread-5] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n","2026-02-19 08:42:58,826 [Thread-5] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n","2026-02-19 08:42:58,829 [Thread-5] INFO  org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory - No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2026-02-19 08:42:58,830 [Thread-5] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n","2026-02-19 08:42:58,830 [Thread-5] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2026-02-19 08:42:58,831 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n","2026-02-19 08:42:58,916 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1020340557_0001_m_000000_0\n","2026-02-19 08:42:58,917 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n","2026-02-19 08:42:58,991 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory - No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2026-02-19 08:42:58,992 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n","2026-02-19 08:42:58,992 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2026-02-19 08:42:59,032 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n","2026-02-19 08:42:59,054 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n","Total Length = 534792\n","Input split[0]:\n","   Length = 534792\n","   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n","   Locations:\n","\n","-----------------------\n","\n","2026-02-19 08:42:59,091 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.builtin.PigStorage - Using PigTextInputFormat\n","2026-02-19 08:42:59,102 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/content/data/pig_out/survey_clean/part-m-00000:0+534792\n","2026-02-19 08:42:59,255 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1020340557_0001\n","2026-02-19 08:42:59,255 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases race_count,race_group,survey_clean,survey_valid\n","2026-02-19 08:42:59,256 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: survey_clean[3,15],survey_clean[-1,-1],survey_valid[21,15],race_count[24,13],race_group[23,13] C: race_count[24,13],race_group[23,13] R: race_count[24,13]\n","2026-02-19 08:42:59,262 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 0% complete\n","2026-02-19 08:42:59,262 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1020340557_0001]\n","2026-02-19 08:42:59,278 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n","2026-02-19 08:42:59,278 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n","2026-02-19 08:42:59,278 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n","2026-02-19 08:42:59,278 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n","2026-02-19 08:42:59,278 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n","2026-02-19 08:42:59,290 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n","2026-02-19 08:42:59,317 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (G1 Old Gen) of size 1048576000 to monitor. collectionUsageThreshold = 734003200, usageThreshold = 734003200\n","2026-02-19 08:42:59,322 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.data.SchemaTupleBackend - Key [pig.schematuple] was not set... will not generate code.\n","2026-02-19 08:42:59,402 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: survey_clean[3,15],survey_clean[-1,-1],survey_valid[21,15],race_count[24,13],race_group[23,13] C: race_count[24,13],race_group[23,13] R: race_count[24,13]\n","2026-02-19 08:43:00,050 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n","2026-02-19 08:43:00,050 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n","2026-02-19 08:43:00,050 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n","2026-02-19 08:43:00,050 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 61243; bufvoid = 104857600\n","2026-02-19 08:43:00,053 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26199128(104796512); length = 15269/6553600\n","2026-02-19 08:43:00,167 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigCombiner$Combine - Aliases being processed per job phase (AliasName[line,offset]): M: survey_clean[3,15],survey_clean[-1,-1],survey_valid[21,15],race_count[24,13],race_group[23,13] C: race_count[24,13],race_group[23,13] R: race_count[24,13]\n","2026-02-19 08:43:00,267 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n","2026-02-19 08:43:00,304 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1020340557_0001_m_000000_0 is done. And is in the process of committing\n","2026-02-19 08:43:00,311 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n","2026-02-19 08:43:00,311 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1020340557_0001_m_000000_0' done.\n","2026-02-19 08:43:00,329 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1020340557_0001_m_000000_0: Counters: 18\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=539420\n","\t\tFILE: Number of bytes written=700006\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tMap input records=3818\n","\t\tMap output records=3818\n","\t\tMap output bytes=61243\n","\t\tMap output materialized bytes=323\n","\t\tInput split bytes=379\n","\t\tCombine input records=3818\n","\t\tCombine output records=11\n","\t\tSpilled Records=11\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=0\n","\t\tGC time elapsed (ms)=54\n","\t\tTotal committed heap usage (bytes)=179306496\n","\tFile Input Format Counters \n","\t\tBytes Read=0\n","2026-02-19 08:43:00,329 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1020340557_0001_m_000000_0\n","2026-02-19 08:43:00,330 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n","2026-02-19 08:43:00,343 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1020340557_0001_r_000000_0\n","2026-02-19 08:43:00,345 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n","2026-02-19 08:43:00,377 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory - No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2026-02-19 08:43:00,377 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n","2026-02-19 08:43:00,377 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2026-02-19 08:43:00,384 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n","2026-02-19 08:43:00,387 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@29268bca\n","2026-02-19 08:43:00,388 [pool-4-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 08:43:00,433 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=734003200, maxSingleShuffleLimit=183500800, mergeThreshold=484442144, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n","2026-02-19 08:43:00,445 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1020340557_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n","2026-02-19 08:43:00,610 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1020340557_0001_m_000000_0 decomp: 319 len: 323 to MEMORY\n","2026-02-19 08:43:00,622 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 319 bytes from map-output for attempt_local1020340557_0001_m_000000_0\n","2026-02-19 08:43:00,642 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 319, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->319\n","2026-02-19 08:43:00,645 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n","2026-02-19 08:43:00,649 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n","2026-02-19 08:43:00,649 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n","2026-02-19 08:43:00,685 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n","2026-02-19 08:43:00,686 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 309 bytes\n","2026-02-19 08:43:00,697 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 319 bytes to disk to satisfy reduce memory limit\n","2026-02-19 08:43:00,698 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 323 bytes from disk\n","2026-02-19 08:43:00,699 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n","2026-02-19 08:43:00,707 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n","2026-02-19 08:43:00,710 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 309 bytes\n","2026-02-19 08:43:00,711 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n","2026-02-19 08:43:00,731 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory - No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2026-02-19 08:43:00,734 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n","2026-02-19 08:43:00,734 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2026-02-19 08:43:00,741 [pool-4-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n","2026-02-19 08:43:00,743 [pool-4-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (G1 Old Gen) of size 1048576000 to monitor. collectionUsageThreshold = 734003200, usageThreshold = 734003200\n","2026-02-19 08:43:00,743 [pool-4-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n","2026-02-19 08:43:00,758 [pool-4-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: survey_clean[3,15],survey_clean[-1,-1],survey_valid[21,15],race_count[24,13],race_group[23,13] C: race_count[24,13],race_group[23,13] R: race_count[24,13]\n","2026-02-19 08:43:00,770 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 12% complete\n","2026-02-19 08:43:00,770 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1020340557_0001]\n","2026-02-19 08:43:00,776 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1020340557_0001_r_000000_0 is done. And is in the process of committing\n","2026-02-19 08:43:00,798 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n","2026-02-19 08:43:00,800 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1020340557_0001_r_000000_0 is allowed to commit now\n","2026-02-19 08:43:00,820 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1020340557_0001_r_000000_0' to file:/tmp/temp-1457527520/tmp-1542315493\n","2026-02-19 08:43:00,824 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n","2026-02-19 08:43:00,824 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1020340557_0001_r_000000_0' done.\n","2026-02-19 08:43:00,828 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1020340557_0001_r_000000_0: Counters: 24\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=540098\n","\t\tFILE: Number of bytes written=700636\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tCombine input records=0\n","\t\tCombine output records=0\n","\t\tReduce input groups=11\n","\t\tReduce shuffle bytes=323\n","\t\tReduce input records=11\n","\t\tReduce output records=11\n","\t\tSpilled Records=11\n","\t\tShuffled Maps =1\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=1\n","\t\tGC time elapsed (ms)=36\n","\t\tTotal committed heap usage (bytes)=246415360\n","\tShuffle Errors\n","\t\tBAD_ID=0\n","\t\tCONNECTION=0\n","\t\tIO_ERROR=0\n","\t\tWRONG_LENGTH=0\n","\t\tWRONG_MAP=0\n","\t\tWRONG_REDUCE=0\n","\tFile Output Format Counters \n","\t\tBytes Written=0\n","2026-02-19 08:43:00,830 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1020340557_0001_r_000000_0\n","2026-02-19 08:43:00,830 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n","2026-02-19 08:43:01,043 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 25% complete\n","2026-02-19 08:43:01,060 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 08:43:01,089 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 08:43:01,092 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n","2026-02-19 08:43:01,096 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 08:43:01,161 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n","2026-02-19 08:43:01,164 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n","2026-02-19 08:43:01,165 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n","2026-02-19 08:43:01,165 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n","2026-02-19 08:43:01,169 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=295\n","2026-02-19 08:43:01,170 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n","2026-02-19 08:43:01,178 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n","2026-02-19 08:43:01,231 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n","2026-02-19 08:43:01,238 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 08:43:01,251 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n","2026-02-19 08:43:01,260 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n","2026-02-19 08:43:01,260 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n","2026-02-19 08:43:01,260 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n","2026-02-19 08:43:01,269 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n","2026-02-19 08:43:01,304 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1873993109_0002\n","2026-02-19 08:43:01,305 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n","2026-02-19 08:43:01,536 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n","2026-02-19 08:43:01,537 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n","2026-02-19 08:43:01,553 [Thread-14] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n","2026-02-19 08:43:01,553 [Thread-14] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n","2026-02-19 08:43:01,553 [Thread-14] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n","2026-02-19 08:43:01,554 [Thread-14] INFO  org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory - No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2026-02-19 08:43:01,554 [Thread-14] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n","2026-02-19 08:43:01,554 [Thread-14] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2026-02-19 08:43:01,555 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n","2026-02-19 08:43:01,568 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1873993109_0002_m_000000_0\n","2026-02-19 08:43:01,568 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n","2026-02-19 08:43:01,613 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory - No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2026-02-19 08:43:01,615 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n","2026-02-19 08:43:01,615 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2026-02-19 08:43:01,616 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n","2026-02-19 08:43:01,625 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n","Total Length = 295\n","Input split[0]:\n","   Length = 295\n","   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n","   Locations:\n","\n","-----------------------\n","\n","2026-02-19 08:43:01,643 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp-1457527520/tmp-1542315493/part-r-00000:0+295\n","2026-02-19 08:43:01,904 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n","2026-02-19 08:43:01,904 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n","2026-02-19 08:43:01,904 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n","2026-02-19 08:43:01,904 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n","2026-02-19 08:43:01,904 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n","2026-02-19 08:43:01,916 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n","2026-02-19 08:43:01,931 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (G1 Old Gen) of size 1048576000 to monitor. collectionUsageThreshold = 734003200, usageThreshold = 734003200\n","2026-02-19 08:43:01,931 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n","2026-02-19 08:43:01,935 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: race_order[25,13] C:  R: \n","2026-02-19 08:43:01,943 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n","2026-02-19 08:43:01,943 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n","2026-02-19 08:43:01,943 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n","2026-02-19 08:43:01,943 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 180; bufvoid = 104857600\n","2026-02-19 08:43:01,943 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214356(104857424); length = 41/6553600\n","2026-02-19 08:43:01,946 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n","2026-02-19 08:43:01,956 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1873993109_0002_m_000000_0 is done. And is in the process of committing\n","2026-02-19 08:43:01,961 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n","2026-02-19 08:43:01,961 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1873993109_0002_m_000000_0' done.\n","2026-02-19 08:43:01,962 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1873993109_0002_m_000000_0: Counters: 17\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=540845\n","\t\tFILE: Number of bytes written=1382320\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tMap input records=11\n","\t\tMap output records=11\n","\t\tMap output bytes=180\n","\t\tMap output materialized bytes=208\n","\t\tInput split bytes=380\n","\t\tCombine input records=0\n","\t\tSpilled Records=11\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=0\n","\t\tGC time elapsed (ms)=31\n","\t\tTotal committed heap usage (bytes)=312475648\n","\tFile Input Format Counters \n","\t\tBytes Read=0\n","2026-02-19 08:43:01,962 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1873993109_0002_m_000000_0\n","2026-02-19 08:43:01,964 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n","2026-02-19 08:43:01,968 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n","2026-02-19 08:43:01,968 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1873993109_0002_r_000000_0\n","2026-02-19 08:43:02,007 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory - No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2026-02-19 08:43:02,008 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n","2026-02-19 08:43:02,008 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2026-02-19 08:43:02,021 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n","2026-02-19 08:43:02,021 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3d3794ae\n","2026-02-19 08:43:02,022 [pool-9-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 08:43:02,026 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=734003200, maxSingleShuffleLimit=183500800, mergeThreshold=484442144, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n","2026-02-19 08:43:02,029 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1873993109_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n","2026-02-19 08:43:02,035 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1873993109_0002_m_000000_0 decomp: 204 len: 208 to MEMORY\n","2026-02-19 08:43:02,037 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1873993109_0002\n","2026-02-19 08:43:02,037 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases race_order\n","2026-02-19 08:43:02,037 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: race_order[25,13] C:  R: \n","2026-02-19 08:43:02,038 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 204 bytes from map-output for attempt_local1873993109_0002_m_000000_0\n","2026-02-19 08:43:02,039 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 204, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->204\n","2026-02-19 08:43:02,039 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n","2026-02-19 08:43:02,041 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n","2026-02-19 08:43:02,041 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n","2026-02-19 08:43:02,042 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 37% complete\n","2026-02-19 08:43:02,045 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1873993109_0002]\n","2026-02-19 08:43:02,045 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n","2026-02-19 08:43:02,045 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 190 bytes\n","2026-02-19 08:43:02,048 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 204 bytes to disk to satisfy reduce memory limit\n","2026-02-19 08:43:02,048 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 208 bytes from disk\n","2026-02-19 08:43:02,048 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n","2026-02-19 08:43:02,050 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n","2026-02-19 08:43:02,052 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 190 bytes\n","2026-02-19 08:43:02,053 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n","2026-02-19 08:43:02,061 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory - No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2026-02-19 08:43:02,061 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n","2026-02-19 08:43:02,061 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2026-02-19 08:43:02,067 [pool-9-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (G1 Old Gen) of size 1048576000 to monitor. collectionUsageThreshold = 734003200, usageThreshold = 734003200\n","2026-02-19 08:43:02,069 [pool-9-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n","2026-02-19 08:43:02,081 [pool-9-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: race_order[25,13] C:  R: \n","2026-02-19 08:43:02,096 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1873993109_0002_r_000000_0 is done. And is in the process of committing\n","2026-02-19 08:43:02,114 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n","2026-02-19 08:43:02,115 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1873993109_0002_r_000000_0 is allowed to commit now\n","2026-02-19 08:43:02,147 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1873993109_0002_r_000000_0' to file:/tmp/temp-1457527520/tmp219122302\n","2026-02-19 08:43:02,150 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n","2026-02-19 08:43:02,150 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1873993109_0002_r_000000_0' done.\n","2026-02-19 08:43:02,150 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1873993109_0002_r_000000_0: Counters: 24\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=541293\n","\t\tFILE: Number of bytes written=1382589\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tCombine input records=0\n","\t\tCombine output records=0\n","\t\tReduce input groups=1\n","\t\tReduce shuffle bytes=208\n","\t\tReduce input records=11\n","\t\tReduce output records=1\n","\t\tSpilled Records=11\n","\t\tShuffled Maps =1\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=1\n","\t\tGC time elapsed (ms)=0\n","\t\tTotal committed heap usage (bytes)=312475648\n","\tShuffle Errors\n","\t\tBAD_ID=0\n","\t\tCONNECTION=0\n","\t\tIO_ERROR=0\n","\t\tWRONG_LENGTH=0\n","\t\tWRONG_MAP=0\n","\t\tWRONG_REDUCE=0\n","\tFile Output Format Counters \n","\t\tBytes Written=0\n","2026-02-19 08:43:02,153 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1873993109_0002_r_000000_0\n","2026-02-19 08:43:02,153 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n","2026-02-19 08:43:02,308 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 50% complete\n","2026-02-19 08:43:02,312 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 08:43:02,315 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 08:43:02,318 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 08:43:02,326 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n","2026-02-19 08:43:02,327 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n","2026-02-19 08:43:02,327 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n","2026-02-19 08:43:02,327 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n","2026-02-19 08:43:02,331 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n","2026-02-19 08:43:02,359 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n","2026-02-19 08:43:02,364 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 08:43:02,374 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n","2026-02-19 08:43:02,381 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n","2026-02-19 08:43:02,381 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n","2026-02-19 08:43:02,381 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n","2026-02-19 08:43:02,386 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n","2026-02-19 08:43:02,432 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1159435036_0003\n","2026-02-19 08:43:02,432 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n","2026-02-19 08:43:02,583 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n","2026-02-19 08:43:02,584 [Thread-21] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n","2026-02-19 08:43:02,598 [Thread-21] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n","2026-02-19 08:43:02,599 [Thread-21] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n","2026-02-19 08:43:02,599 [Thread-21] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n","2026-02-19 08:43:02,599 [Thread-21] INFO  org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory - No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2026-02-19 08:43:02,600 [Thread-21] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n","2026-02-19 08:43:02,600 [Thread-21] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2026-02-19 08:43:02,600 [Thread-21] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n","2026-02-19 08:43:02,615 [Thread-21] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n","2026-02-19 08:43:02,616 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1159435036_0003_m_000000_0\n","2026-02-19 08:43:02,641 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory - No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2026-02-19 08:43:02,641 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n","2026-02-19 08:43:02,641 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2026-02-19 08:43:02,641 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n","2026-02-19 08:43:02,645 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n","Total Length = 295\n","Input split[0]:\n","   Length = 295\n","   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n","   Locations:\n","\n","-----------------------\n","\n","2026-02-19 08:43:02,651 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp-1457527520/tmp-1542315493/part-r-00000:0+295\n","2026-02-19 08:43:02,704 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n","2026-02-19 08:43:02,704 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n","2026-02-19 08:43:02,704 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n","2026-02-19 08:43:02,704 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n","2026-02-19 08:43:02,704 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n","2026-02-19 08:43:02,706 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n","2026-02-19 08:43:02,711 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (G1 Old Gen) of size 1048576000 to monitor. collectionUsageThreshold = 734003200, usageThreshold = 734003200\n","2026-02-19 08:43:02,711 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n","2026-02-19 08:43:02,715 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n","2026-02-19 08:43:02,726 [Thread-21] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n","2026-02-19 08:43:02,737 [Thread-21] WARN  org.apache.hadoop.mapred.LocalJobRunner - job_local1159435036_0003\n","java.lang.Exception: java.io.IOException: Deserialization error: Cannot invoke \"org.apache.pig.impl.plan.OperatorKey.hashCode()\" because \"this.mKey\" is null\n","\tat org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)\n","\tat org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)\n","Caused by: java.io.IOException: Deserialization error: Cannot invoke \"org.apache.pig.impl.plan.OperatorKey.hashCode()\" because \"this.mKey\" is null\n","\tat org.apache.pig.impl.util.ObjectSerializer.deserialize(ObjectSerializer.java:62)\n","\tat org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapBase.setup(PigGenericMapBase.java:183)\n","\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:142)\n","\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:800)\n","\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:348)\n","\tat org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n","\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n","\tat java.base/java.lang.Thread.run(Thread.java:840)\n","Caused by: java.lang.NullPointerException: Cannot invoke \"org.apache.pig.impl.plan.OperatorKey.hashCode()\" because \"this.mKey\" is null\n","\tat org.apache.pig.impl.plan.Operator.hashCode(Operator.java:106)\n","\tat java.base/java.util.HashMap.hash(HashMap.java:338)\n","\tat java.base/java.util.HashMap.readObject(HashMap.java:1553)\n","\tat java.base/jdk.internal.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)\n","\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n","\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n","\tat java.base/java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1100)\n","\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2423)\n","\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2257)\n","\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1733)\n","\tat java.base/java.io.ObjectInputStream$FieldValues.<init>(ObjectInputStream.java:2606)\n","\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2457)\n","\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2257)\n","\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1733)\n","\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:509)\n","\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:467)\n","\tat java.base/java.util.ArrayList.readObject(ArrayList.java:899)\n","\tat java.base/jdk.internal.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)\n","\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n","\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n","\tat java.base/java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1100)\n","\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2423)\n","\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2257)\n","\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1733)\n","\tat java.base/java.io.ObjectInputStream$FieldValues.<init>(ObjectInputStream.java:2606)\n","\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2457)\n","\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2257)\n","\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1733)\n","\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:509)\n","\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:467)\n","\tat java.base/java.util.ArrayList.readObject(ArrayList.java:899)\n","\tat java.base/jdk.internal.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)\n","\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n","\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n","\tat java.base/java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1100)\n","\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2423)\n","\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2257)\n","\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1733)\n","\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:509)\n","\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:467)\n","\tat java.base/java.util.HashMap.readObject(HashMap.java:1552)\n","\tat java.base/jdk.internal.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)\n","\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n","\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n","\tat java.base/java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1100)\n","\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2423)\n","\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2257)\n","\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1733)\n","\tat java.base/java.io.ObjectInputStream$FieldValues.<init>(ObjectInputStream.java:2606)\n","\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2457)\n","\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2257)\n","\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1733)\n","\tat java.base/java.io.ObjectInputStream$FieldValues.<init>(ObjectInputStream.java:2606)\n","\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2457)\n","\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2257)\n","\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1733)\n","\tat java.base/java.io.ObjectInputStream$FieldValues.<init>(ObjectInputStream.java:2606)\n","\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2457)\n","\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2257)\n","\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1733)\n","\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:509)\n","\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:467)\n","\tat java.base/java.util.ArrayList.readObject(ArrayList.java:899)\n","\tat java.base/jdk.internal.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)\n","\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n","\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n","\tat java.base/java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1100)\n","\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2423)\n","\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2257)\n","\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1733)\n","\tat java.base/java.io.ObjectInputStream$FieldValues.<init>(ObjectInputStream.java:2606)\n","\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2457)\n","\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2257)\n","\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1733)\n","\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:509)\n","\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:467)\n","\tat java.base/java.util.HashMap.readObject(HashMap.java:1552)\n","\tat java.base/jdk.internal.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)\n","\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n","\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n","\tat java.base/java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1100)\n","\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2423)\n","\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2257)\n","\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1733)\n","\tat java.base/java.io.ObjectInputStream$FieldValues.<init>(ObjectInputStream.java:2606)\n","\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2457)\n","\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2257)\n","\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1733)\n","\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:509)\n","\tat java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:467)\n","\tat org.apache.pig.impl.util.ObjectSerializer.deserialize(ObjectSerializer.java:60)\n","\t... 10 more\n","2026-02-19 08:43:02,888 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1159435036_0003\n","2026-02-19 08:43:02,889 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases race_order\n","2026-02-19 08:43:02,889 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: race_order[25,13] C:  R: \n","2026-02-19 08:43:02,893 [main] WARN  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Ooops! Some job has failed! Specify -stop_on_failure if you want Pig to stop immediately on failure.\n","2026-02-19 08:43:02,893 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - job job_local1159435036_0003 has failed! Stop running all dependent jobs\n","2026-02-19 08:43:02,893 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 100% complete\n","2026-02-19 08:43:02,898 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 08:43:02,902 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 08:43:02,904 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil - 1 map reduce job(s) failed!\n","2026-02-19 08:43:02,909 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats - Script Statistics: \n","\n","HadoopVersion\tPigVersion\tUserId\tStartedAt\tFinishedAt\tFeatures\n","3.4.2\t0.17.0\troot\t2026-02-19 08:42:57\t2026-02-19 08:43:02\tGROUP_BY,ORDER_BY,FILTER,LIMIT\n","\n","Some jobs have failed! Stop running all dependent jobs\n","\n","Job Stats (time in seconds):\n","JobId\tMaps\tReduces\tMaxMapTime\tMinMapTime\tAvgMapTime\tMedianMapTime\tMaxReduceTime\tMinReduceTime\tAvgReduceTime\tMedianReducetime\tAlias\tFeature\tOutputs\n","job_local1020340557_0001\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\trace_count,race_group,survey_clean,survey_valid\tGROUP_BY,COMBINER\t\n","job_local1873993109_0002\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\trace_order\tSAMPLER\t\n","\n","Failed Jobs:\n","JobId\tAlias\tFeature\tMessage\tOutputs\n","job_local1159435036_0003\trace_order\tORDER_BY,COMBINER\tMessage: Job failed!\t\n","\n","Input(s):\n","Successfully read 3818 records from: \"/content/data/pig_out/survey_clean\"\n","\n","Output(s):\n","\n","Counters:\n","Total records written : 0\n","Total bytes written : 0\n","Spillable Memory Manager spill count : 0\n","Total bags proactively spilled: 0\n","Total records proactively spilled: 0\n","\n","Job DAG:\n","job_local1020340557_0001\t->\tjob_local1873993109_0002,\n","job_local1873993109_0002\t->\tjob_local1159435036_0003,\n","job_local1159435036_0003\t->\tnull,\n","null\n","\n","\n","2026-02-19 08:43:02,912 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 08:43:02,916 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 08:43:02,918 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 08:43:02,948 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 08:43:02,953 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 08:43:02,957 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n","2026-02-19 08:43:02,965 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Some jobs have failed! Stop running all dependent jobs\n","2026-02-19 08:43:02,969 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1066: Unable to open iterator for alias top3_race\n","Details at logfile: /content/pig_1771490575827.log\n","2026-02-19 08:43:02,992 [main] INFO  org.apache.pig.Main - Pig script completed in 7 seconds and 520 milliseconds (7520 ms)\n","\n","Verificaci√≥n r√°pida 3.2:\n","- Deben aparecer 3 filas con formato (RACE,conteo) en el DUMP\n","- Debe aparecer 'Success!' al final del log\n"]}],"source":["# Ejecutar tratamiento 3.2 (Top 3 RACE) y dejar pista clara de √©xito\n","\n","!pig -x local -f tratamiento_top3_race.pig | tee top3_race.log\n","\n","print(\"\\nVerificaci√≥n r√°pida 3.2:\")\n","print(\"- Deben aparecer 3 filas con formato (RACE,conteo) en el DUMP\")\n","print(\"- Debe aparecer 'Success!' al final del log\")\n","\n","!grep -n \"Success!\" top3_race.log | tail -n 1\n","!grep -E \"^\\(.*,[0-9]+\\)$\" top3_race.log | head -n 3"]},{"cell_type":"markdown","id":"64049fc5","metadata":{"id":"64049fc5"},"source":["## Conclusiones (Secci√≥n 3.2)\n","He ejecutado el script tratamiento_top3_race.pig en modo local y he mostrado el resultado directamente en pantalla usando DUMP, lo que deja evidencia visible en el cuaderno.\n","Como tratamiento interesante, he calculado el Top 3 de valores m√°s frecuentes de la variable RACE a partir de los datos ya limpiados (survey_clean). El resultado obtenido es:\n","\n","White: 3313\n","\n","Black or African American: 253\n","\n","Asian: 120\n","\n","Este paso completa el apartado 3.2 con una agregaci√≥n sencilla (GROUP + COUNT + ORDER + LIMIT) y deja el dataset preparado para continuar con Spark/Hive."]},{"cell_type":"markdown","id":"325dffca","metadata":{"id":"325dffca"},"source":["## 4) Spark (PySpark) ‚Üí Hive\n","En esta secci√≥n voy a usar PySpark para leer los datos limpios que gener√© con Pig.\n","Como el output de Pig no trae cabecera garantizada, aplicar√© el esquema usando las cabeceras de los CSV originales.\n","Despu√©s guardar√© los dos DataFrames en Hive como `tabla_survey` y `tabla_genotyping`.\n","As√≠ dejo preparadas dos tablas relacionales para poder hacer JOIN real en la Secci√≥n 5."]},{"cell_type":"code","execution_count":17,"id":"bac6f32a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bac6f32a","executionInfo":{"status":"ok","timestamp":1771489998428,"user_tz":-60,"elapsed":3424,"user":{"displayName":"Alfredo Ledesma Ruiz","userId":"02263706330541384863"}},"outputId":"2b6fe883-063a-40a0-e0a8-16dc91767949"},"outputs":[{"output_type":"stream","name":"stdout","text":["spark.version: 4.0.2\n"]}],"source":["# Secci√≥n 4 ‚Äî Configurar Spark con soporte Hive\n","\n","import os\n","\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-17-openjdk-amd64\"\n","\n","!pip -q install pyspark findspark\n","\n","import findspark\n","findspark.init()\n","\n","from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder \\\n","    .master(\"local[*]\") \\\n","    .appName(\"BDA03_Spark_Hive\") \\\n","    .config(\"spark.sql.warehouse.dir\", \"/content/spark-warehouse\") \\\n","    .enableHiveSupport() \\\n","    .getOrCreate()\n","\n","print(\"spark.version:\", spark.version)"]},{"cell_type":"code","execution_count":18,"id":"e03e4894","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"e03e4894","executionInfo":{"status":"ok","timestamp":1771490020059,"user_tz":-60,"elapsed":6610,"user":{"displayName":"Alfredo Ledesma Ruiz","userId":"02263706330541384863"}},"outputId":"5f71a277-d2ad-422e-da3f-e85007985002"},"outputs":[{"output_type":"stream","name":"stdout","text":["Schema tabla_survey:\n","root\n"," |-- SUBJECT_ID: string (nullable = true)\n"," |-- AGE: string (nullable = true)\n"," |-- RACE: string (nullable = true)\n"," |-- T1D_HIST: string (nullable = true)\n"," |-- AUTO_HIST: string (nullable = true)\n"," |-- AUTO_COND: string (nullable = true)\n"," |-- AUTO_COND_4_TEXT: string (nullable = true)\n"," |-- T1D_DIAG: string (nullable = true)\n"," |-- T1D_DIAG_AGE: string (nullable = true)\n"," |-- T1D_HOSP: string (nullable = true)\n"," |-- DKA: string (nullable = true)\n"," |-- GRS_HLA: string (nullable = true)\n"," |-- GnonHLA: string (nullable = true)\n"," |-- GRS: string (nullable = true)\n"," |-- Risk: string (nullable = true)\n","\n","Muestra tabla_survey:\n","+--------------+---+-----+----------+---------+----------------------------------------------------------------------------------------------------------------------------+----------------+--------+--------------+--------------+--------------+-------+-------+------+--------+\n","|SUBJECT_ID    |AGE|RACE |T1D_HIST  |AUTO_HIST|AUTO_COND                                                                                                                   |AUTO_COND_4_TEXT|T1D_DIAG|T1D_DIAG_AGE  |T1D_HOSP      |DKA           |GRS_HLA|GnonHLA|GRS   |Risk    |\n","+--------------+---+-----+----------+---------+----------------------------------------------------------------------------------------------------------------------------+----------------+--------+--------------+--------------+--------------+-------+-------+------+--------+\n","|10011708520314|6  |White|Yes       |No       |Not applicable                                                                                                              |Not applicable  |No      |Not applicable|Not applicable|Not applicable|1.91   |0.14   |2.06  |Not high|\n","|10021708520764|3  |White|Don't know|Yes      |Thyroid_Hashimotos and_or Graves, Blood relative has been diagnosed with autoimmune disease but I don't know which condition|Not applicable  |No      |Not applicable|Not applicable|Not applicable|-1.41  |1.93   |0.52  |NULL    |\n","|10021708521587|7  |Asian|Don't know|No       |Not applicable                                                                                                              |Not applicable  |No      |Not applicable|Not applicable|Not applicable|-13.66 |0.77   |-12.89|Not high|\n","+--------------+---+-----+----------+---------+----------------------------------------------------------------------------------------------------------------------------+----------------+--------+--------------+--------------+--------------+-------+-------+------+--------+\n","only showing top 3 rows\n","Schema tabla_genotyping:\n","root\n"," |-- FID: string (nullable = true)\n"," |-- contact_key: string (nullable = true)\n"," |-- rs1049225: string (nullable = true)\n"," |-- rs1052553: string (nullable = true)\n"," |-- rs10795791: string (nullable = true)\n"," |-- rs11203203: string (nullable = true)\n"," |-- rs113010081: string (nullable = true)\n"," |-- rs1150743: string (nullable = true)\n"," |-- rs12416116: string (nullable = true)\n"," |-- rs12720356: string (nullable = true)\n"," |-- rs12927355: string (nullable = true)\n"," |-- rs12971201: string (nullable = true)\n"," |-- rs13415583: string (nullable = true)\n"," |-- rs1367728: string (nullable = true)\n"," |-- rs1456988: string (nullable = true)\n"," |-- rs151233: string (nullable = true)\n"," |-- rs1574285: string (nullable = true)\n"," |-- rs1615504: string (nullable = true)\n"," |-- rs1893217: string (nullable = true)\n"," |-- rs193778: string (nullable = true)\n"," |-- rs2045258: string (nullable = true)\n"," |-- rs2071463: string (nullable = true)\n"," |-- rs2076531: string (nullable = true)\n"," |-- rs2111485: string (nullable = true)\n"," |-- rs2143461: string (nullable = true)\n"," |-- rs2194225: string (nullable = true)\n"," |-- rs2239800: string (nullable = true)\n"," |-- rs2256974: string (nullable = true)\n"," |-- rs229533: string (nullable = true)\n"," |-- rs2476601: string (nullable = true)\n"," |-- rs2523409: string (nullable = true)\n"," |-- rs2524089: string (nullable = true)\n"," |-- rs2611215: string (nullable = true)\n"," |-- rs28732101: string (nullable = true)\n"," |-- rs3024505: string (nullable = true)\n"," |-- rs3087243: string (nullable = true)\n"," |-- rs3094165: string (nullable = true)\n"," |-- rs3129722: string (nullable = true)\n"," |-- rs3130933: string (nullable = true)\n"," |-- rs34536443: string (nullable = true)\n"," |-- rs34593439: string (nullable = true)\n"," |-- rs35337543: string (nullable = true)\n"," |-- rs35667974: string (nullable = true)\n"," |-- rs3763305: string (nullable = true)\n"," |-- rs402072: string (nullable = true)\n"," |-- rs41295121: string (nullable = true)\n"," |-- rs436845: string (nullable = true)\n"," |-- rs4820830: string (nullable = true)\n"," |-- rs4849135: string (nullable = true)\n"," |-- rs516246: string (nullable = true)\n"," |-- rs56994090: string (nullable = true)\n"," |-- rs6043409: string (nullable = true)\n"," |-- rs61839660: string (nullable = true)\n"," |-- rs62447205: string (nullable = true)\n"," |-- rs635688: string (nullable = true)\n"," |-- rs6518350: string (nullable = true)\n"," |-- rs653178: string (nullable = true)\n"," |-- rs6691977: string (nullable = true)\n"," |-- rs689: string (nullable = true)\n"," |-- rs6903608: string (nullable = true)\n"," |-- rs6906897: string (nullable = true)\n"," |-- rs6935715: string (nullable = true)\n"," |-- rs705704: string (nullable = true)\n"," |-- rs72727394: string (nullable = true)\n"," |-- rs72853903: string (nullable = true)\n"," |-- rs72928038: string (nullable = true)\n"," |-- rs757411: string (nullable = true)\n"," |-- rs7745656: string (nullable = true)\n"," |-- rs7780389: string (nullable = true)\n"," |-- rs917911: string (nullable = true)\n"," |-- rs9268633: string (nullable = true)\n"," |-- rs9271366: string (nullable = true)\n"," |-- rs9273363: string (nullable = true)\n"," |-- rs9357152: string (nullable = true)\n"," |-- rs9469341: string (nullable = true)\n"," |-- rs9585056: string (nullable = true)\n","\n","Muestra tabla_genotyping:\n","+--------------+------------+---------+---------+----------+----------+-----------+---------+----------+----------+----------+----------+----------+---------+---------+--------+---------+---------+---------+--------+---------+---------+---------+---------+---------+---------+---------+---------+--------+---------+---------+---------+---------+----------+---------+---------+---------+---------+---------+----------+----------+----------+----------+---------+--------+----------+--------+---------+---------+--------+----------+---------+----------+----------+--------+---------+--------+---------+-----+---------+---------+---------+--------+----------+----------+----------+--------+---------+---------+--------+---------+---------+---------+---------+---------+---------+\n","|FID           |contact_key |rs1049225|rs1052553|rs10795791|rs11203203|rs113010081|rs1150743|rs12416116|rs12720356|rs12927355|rs12971201|rs13415583|rs1367728|rs1456988|rs151233|rs1574285|rs1615504|rs1893217|rs193778|rs2045258|rs2071463|rs2076531|rs2111485|rs2143461|rs2194225|rs2239800|rs2256974|rs229533|rs2476601|rs2523409|rs2524089|rs2611215|rs28732101|rs3024505|rs3087243|rs3094165|rs3129722|rs3130933|rs34536443|rs34593439|rs35337543|rs35667974|rs3763305|rs402072|rs41295121|rs436845|rs4820830|rs4849135|rs516246|rs56994090|rs6043409|rs61839660|rs62447205|rs635688|rs6518350|rs653178|rs6691977|rs689|rs6903608|rs6906897|rs6935715|rs705704|rs72727394|rs72853903|rs72928038|rs757411|rs7745656|rs7780389|rs917911|rs9268633|rs9271366|rs9273363|rs9357152|rs9469341|rs9585056|\n","+--------------+------------+---------+---------+----------+----------+-----------+---------+----------+----------+----------+----------+----------+---------+---------+--------+---------+---------+---------+--------+---------+---------+---------+---------+---------+---------+---------+---------+--------+---------+---------+---------+---------+----------+---------+---------+---------+---------+---------+----------+----------+----------+----------+---------+--------+----------+--------+---------+---------+--------+----------+---------+----------+----------+--------+---------+--------+---------+-----+---------+---------+---------+--------+----------+----------+----------+--------+---------+---------+--------+---------+---------+---------+---------+---------+---------+\n","|10011708520314|CONTACT10085|C:C      |A:A      |A:G       |A:G       |T:T        |A:G      |C:C       |T:T       |T:C       |A:G       |G:T       |A:G      |G:T      |A:G     |G:G      |G:G      |T:T      |T:T     |C:T      |G:G      |T:T      |A:G      |C:C      |A:A      |C:T      |T:G      |A:A     |G:G      |C:T      |A:A      |C:C      |C:C       |C:C      |A:G      |C:T      |C:C      |G:G      |G:G       |G:G       |G:G       |A:A       |A:G      |A:G     |C:T       |C:T     |T:C      |G:G      |A:G     |T:T       |A:G      |C:C       |A:A       |C:T     |A:A      |G:G     |T:T      |A:A  |T:T      |C:C      |T:T      |G:G     |C:T       |C:T       |G:G       |C:T     |G:T      |C:C      |G:T     |A:G      |A:A      |A:C      |A:A      |A:G      |T:T      |\n","|10021708520764|CONTACT14053|C:C      |A:A      |G:G       |A:A       |T:T        |G:G      |C:C       |T:T       |C:C       |G:G       |T:T       |G:G      |G:T      |G:G     |G:T      |A:G      |C:T      |C:T     |C:C      |A:G      |T:T      |G:G      |C:C      |A:G      |T:T      |G:G      |C:C     |A:G      |C:C      |A:C      |C:C      |C:C       |C:T      |A:G      |C:C      |C:C      |G:G      |G:G       |G:G       |G:G       |A:A       |G:G      |A:A     |C:C       |T:T     |T:T      |G:G      |G:G     |T:T       |A:A      |C:C       |A:G       |T:T     |A:A      |A:G     |T:T      |A:T  |C:T      |C:C      |T:T      |A:G     |C:C       |C:C       |G:G       |C:C     |T:T      |C:C      |G:T     |G:G      |A:A      |C:C      |A:G      |A:G      |C:T      |\n","|10021708521587|CONTACT11350|C:C      |A:G      |A:G       |G:G       |T:T        |A:A      |A:A       |T:T       |T:T       |G:G       |T:T       |G:G      |G:G      |A:A     |G:T      |A:G      |T:T      |T:T     |C:C      |A:A      |C:C      |A:G      |C:C      |A:A      |T:T      |G:G      |A:C     |G:G      |T:T      |A:A      |C:C      |C:C       |C:C      |A:A      |T:T      |C:C      |G:G      |G:G       |G:G       |G:G       |A:A       |G:G      |A:A     |C:C       |T:T     |T:T      |T:T      |G:G     |T:T       |A:G      |C:C       |A:A       |C:C     |A:A      |A:G     |C:T      |A:A  |T:T      |C:C      |T:T      |A:G     |C:T       |C:C       |A:G       |C:T     |T:T      |C:C      |T:T     |A:A      |G:G      |C:C      |A:A      |G:G      |C:T      |\n","+--------------+------------+---------+---------+----------+----------+-----------+---------+----------+----------+----------+----------+----------+---------+---------+--------+---------+---------+---------+--------+---------+---------+---------+---------+---------+---------+---------+---------+--------+---------+---------+---------+---------+----------+---------+---------+---------+---------+---------+----------+----------+----------+----------+---------+--------+----------+--------+---------+---------+--------+----------+---------+----------+----------+--------+---------+--------+---------+-----+---------+---------+---------+--------+----------+----------+----------+--------+---------+---------+--------+---------+---------+---------+---------+---------+---------+\n","only showing top 3 rows\n","Tablas Hive creadas:\n","+---------+----------------+-----------+\n","|namespace|tableName       |isTemporary|\n","+---------+----------------+-----------+\n","|default  |tabla_genotyping|false      |\n","|default  |tabla_survey    |false      |\n","+---------+----------------+-----------+\n","\n","COUNT tabla_survey:\n","+-----+\n","|total|\n","+-----+\n","| 3818|\n","+-----+\n","\n","COUNT tabla_genotyping:\n","+-----+\n","|total|\n","+-----+\n","| 3818|\n","+-----+\n","\n"]}],"source":["# Secci√≥n 4 ‚Äî Cargar datos limpios y crear tablas Hive\n","\n","import csv\n","from pyspark.sql.functions import col, trim\n","\n","# 1) Cabeceras desde CSV originales\n","with open('/content/data/csv/survey.csv', 'r', encoding='utf-8') as f:\n","    survey_headers = next(csv.reader(f))\n","\n","with open('/content/data/csv/genotyping.csv', 'r', encoding='utf-8') as f:\n","    genotyping_headers = next(csv.reader(f))\n","\n","# Nombre v√°lido para Spark/Hive (en original viene \"contact key\")\n","genotyping_headers = [h.replace('contact key', 'contact_key') for h in genotyping_headers]\n","\n","# 2) Leer output Pig (sin cabecera) y aplicar esquema\n","survey_df = spark.read.option('header', 'false').option('inferSchema', 'false').csv('/content/data/pig_out/survey_clean') \\\n","    .toDF(*survey_headers)\n","\n","genotyping_df = spark.read.option('header', 'false').option('inferSchema', 'false').csv('/content/data/pig_out/genotyping_clean') \\\n","    .toDF(*genotyping_headers)\n","\n","# 3) Asegurar claves de JOIN como string y normalizadas\n","survey_df = survey_df.withColumn('SUBJECT_ID', trim(col('SUBJECT_ID').cast('string')))\n","genotyping_df = genotyping_df.withColumn('FID', trim(col('FID').cast('string')))\n","\n","# 4) Evidencia m√≠nima: esquema y muestra\n","print('Schema tabla_survey:')\n","survey_df.printSchema()\n","print('Muestra tabla_survey:')\n","survey_df.show(3, truncate=False)\n","\n","print('Schema tabla_genotyping:')\n","genotyping_df.printSchema()\n","print('Muestra tabla_genotyping:')\n","genotyping_df.show(3, truncate=False)\n","\n","# 5) Guardar en Hive (2 tablas)\n","survey_df.write.mode('overwrite').saveAsTable('tabla_survey')\n","genotyping_df.write.mode('overwrite').saveAsTable('tabla_genotyping')\n","\n","# 6) Evidencia m√≠nima en Hive\n","print('Tablas Hive creadas:')\n","spark.sql('SHOW TABLES').show(truncate=False)\n","\n","print('COUNT tabla_survey:')\n","spark.sql('SELECT COUNT(*) AS total FROM tabla_survey').show()\n","print('COUNT tabla_genotyping:')\n","spark.sql('SELECT COUNT(*) AS total FROM tabla_genotyping').show()"]},{"cell_type":"markdown","id":"0dd48fd5","metadata":{"id":"0dd48fd5"},"source":["### Conclusiones (Secci√≥n 4 ‚Äî Spark ‚Üí Hive)\n","He cargado en Spark los ficheros limpios generados con Pig y los he guardado en Hive como **dos tablas** para poder hacer un JOIN real en el siguiente apartado.\n","\n","- **`tabla_survey`** se ha creado con la clave **`SUBJECT_ID`** y el resto de campos cl√≠nicos (**15 columnas**). La muestra confirma que los datos se leen correctamente y que Spark reconoce valores faltantes (por ejemplo, `Risk` aparece como `NULL` en una de las filas mostradas).\n","- **`tabla_genotyping`** se ha creado con la clave **`FID`**, `contact_key` y los marcadores gen√©ticos **`rs*`** (SNPs). La muestra confirma el formato esperado de los genotipos (valores como `A:G`, `C:C`, etc.).\n","- He verificado con `SHOW TABLES` que ambas tablas existen en Hive y aparecen como tablas no temporales: `tabla_survey` y `tabla_genotyping`.\n","- He comprobado con `COUNT(*)` que ambas tablas tienen **3818 filas**, por lo que la carga es consistente.\n","\n","Con esto dejo listo el entorno para las consultas HQL con JOIN usando **`SUBJECT_ID` ‚Üî `FID`**.\n"]},{"cell_type":"markdown","id":"3aa08eb2","metadata":{"id":"3aa08eb2"},"source":["# 5) Consultas HQL con JOIN (Hive)\n","En esta secci√≥n voy a ejecutar dos consultas HQL sobre las tablas Hive creadas.\n","Las dos consultas incluyen JOIN real entre `tabla_survey` y `tabla_genotyping` usando `SUBJECT_ID = FID`.\n","Mostrar√© resultados en pantalla para dejar evidencia evaluable del JOIN y de m√©tricas agregadas.\n","Con esto cierro el apartado de explotaci√≥n en Hive antes de la entrega final."]},{"cell_type":"code","execution_count":11,"id":"a6abf202","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"a6abf202","executionInfo":{"status":"ok","timestamp":1771487471822,"user_tz":-60,"elapsed":3739,"user":{"displayName":"Alfredo Ledesma Ruiz","userId":"02263706330541384863"}},"outputId":"94fc7956-619e-43fa-ac8a-adcc6be5e173"},"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------------------------------------------------------------------------------------------------------------------------------------------------+--------------+\n","|RACE                                                                                                                                                   |total_personas|\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------+--------------+\n","|White                                                                                                                                                  |2918          |\n","|Black or African American                                                                                                                              |518           |\n","|White, Black or African American                                                                                                                       |144           |\n","|Asian                                                                                                                                                  |67            |\n","|White, Asian                                                                                                                                           |62            |\n","|Don't know                                                                                                                                             |37            |\n","|White, Black or African American, Native American, Alaskan Native, Aboriginal Candian, Aboriginal Australian                                           |15            |\n","|Not reported                                                                                                                                           |10            |\n","|Native Hawaiian or other Pacific Islander                                                                                                              |10            |\n","|Black or African American, White                                                                                                                       |8             |\n","|Native American, Alaskan Native, Aboriginal Canadian, Aboriginal Australian                                                                            |8             |\n","|White, Native American, Alaskan Native, Aboriginal Candian, Aboriginal Australian                                                                      |6             |\n","|White, Native Hawaiian or other Pacific Islander                                                                                                       |4             |\n","|Black or African American, Asian                                                                                                                       |2             |\n","|Asian, Native American, Alaskan Native, Aboriginal Candian, Aboriginal Australian                                                                      |2             |\n","|Black or African American, Whit, Native Hawaiian or other Pacific Islander                                                                             |1             |\n","|White, Black or African American, Native Hawaiian or other Pacific Islander, Native American, Alaskan Native, Aboriginal Candian, Aboriginal Australian|1             |\n","|Black or African American,White                                                                                                                        |1             |\n","|Native Hawaiian or other Pacific Islander, White                                                                                                       |1             |\n","|Asian, White                                                                                                                                           |1             |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------+--------------+\n","only showing top 20 rows\n"]}],"source":["# Secci√≥n 5 ‚Äî Consulta HQL #1 (JOIN + GROUP BY + ORDER BY)\n","\n","q1 = \"\"\"\n","SELECT\n","  s.RACE,\n","  COUNT(*) AS total_personas\n","FROM default.tabla_survey s\n","JOIN default.tabla_genotyping g\n","  ON s.SUBJECT_ID = g.FID\n","GROUP BY s.RACE\n","ORDER BY total_personas DESC\n","\"\"\"\n","\n","spark.sql(q1).show(truncate=False)"]},{"cell_type":"code","execution_count":12,"id":"3d410a76","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"3d410a76","executionInfo":{"status":"ok","timestamp":1771487474497,"user_tz":-60,"elapsed":2668,"user":{"displayName":"Alfredo Ledesma Ruiz","userId":"02263706330541384863"}},"outputId":"4cb09408-daf6-4188-916e-060c1c531297"},"outputs":[{"output_type":"stream","name":"stdout","text":["+------------+--------------+---------+\n","|T1D_HIST    |total_personas|media_grs|\n","+------------+--------------+---------+\n","|No          |2444          |-0.657   |\n","|Yes         |926           |0.038    |\n","|Don't know  |444           |-0.708   |\n","|Not reported|4             |2.96     |\n","+------------+--------------+---------+\n","\n"]}],"source":["# Secci√≥n 5 ‚Äî Consulta HQL #2 (JOIN + m√©tricas)\n","\n","q2 = \"\"\"\n","SELECT\n","  s.T1D_HIST,\n","  COUNT(*) AS total_personas,\n","  ROUND(AVG(CAST(s.GRS AS DOUBLE)), 3) AS media_grs\n","FROM default.tabla_survey s\n","JOIN default.tabla_genotyping g\n","  ON s.SUBJECT_ID = g.FID\n","GROUP BY s.T1D_HIST\n","ORDER BY total_personas DESC\n","\"\"\"\n","\n","spark.sql(q2).show(truncate=False)"]},{"cell_type":"markdown","id":"2f2efefa","metadata":{"id":"2f2efefa"},"source":["### Conclusiones (Secci√≥n 5 ‚Äî HQL con JOIN)\n","\n","He ejecutado **dos consultas HQL** que realizan un **JOIN real** entre `tabla_survey` y `tabla_genotyping` usando la clave **`SUBJECT_ID = FID`**.\n","\n","- **Consulta 1 (JOIN + agregaci√≥n por RACE):** he obtenido el recuento de participantes por categor√≠a de `RACE`. En los resultados, la categor√≠a m√°s frecuente es **White (2918)**, seguida de **Black or African American (518)**. Tambi√©n aparecen combinaciones de razas (por ejemplo, **White, Black or African American (144)**) y categor√≠as menos frecuentes como **Asian (67)** o **Don‚Äôt know (37)**.\n","- **Consulta 2 (JOIN + m√©trica con AVG):** he agrupado por `T1D_HIST` y he calculado el total de personas y la **media del GRS**. Los resultados muestran:\n","  - **No:** 2444 personas, media_grs **-0.657**\n","  - **Yes:** 926 personas, media_grs **0.038**\n","  - **Don‚Äôt know:** 444 personas, media_grs **-0.708**\n","  - **Not reported:** 4 personas, media_grs **2.96**\n","\n","Con estas dos consultas queda demostrado el uso de **HQL con JOIN entre dos tablas** y se obtienen resultados interpretables a partir de los datos ya cargados en Hive.\n","\n","> Nota: se observan categor√≠as de `RACE` con variaciones de escritura (por ejemplo, comas/espacios), lo que indica que esta variable podr√≠a normalizarse si el objetivo fuese un an√°lisis estad√≠stico m√°s fino.\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.10"}},"nbformat":4,"nbformat_minor":5}